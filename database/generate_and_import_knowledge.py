"""
ä»PostgreSQLæ¸…æ´—åçš„æ•°æ®ç”ŸæˆçŸ¥è¯†åº“å¹¶ç›´æ¥å¯¼å…¥æ•°æ®åº“ï¼ˆä¸€æ­¥åˆ°ä½ï¼‰

æ­¤è„šæœ¬ï¼š
1. ä»materials_masterè¡¨åŠ è½½æ¸…æ´—åçš„æ•°æ®
2. ç”Ÿæˆæå–è§„åˆ™ã€åŒä¹‰è¯ã€åˆ†ç±»å…³é”®è¯
3. ç›´æ¥å¯¼å…¥åˆ°æ•°æ®åº“è¡¨ä¸­
4. æ— éœ€ä¸­é—´JSONæ–‡ä»¶
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from sqlalchemy import text
from backend.core.config import database_config
from database.material_knowledge_generator import MaterialKnowledgeGenerator
from backend.models.materials import ExtractionRule, Synonym, KnowledgeCategory
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def clear_existing_data(session: AsyncSession):
    """æ¸…ç©ºç°æœ‰çŸ¥è¯†åº“æ•°æ®"""
    logger.info("ğŸ—‘ï¸  æ¸…ç©ºç°æœ‰çŸ¥è¯†åº“æ•°æ®...")
    
    try:
        # æ¸…ç©ºè¡¨ï¼ˆä¿ç•™è¡¨ç»“æ„ï¼‰
        await session.execute(text("TRUNCATE TABLE extraction_rules, synonyms, knowledge_categories RESTART IDENTITY CASCADE"))
        await session.commit()
        logger.info("âœ… å·²æ¸…ç©ºç°æœ‰æ•°æ®")
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºæ•°æ®å¤±è´¥: {e}")
        await session.rollback()
        raise


async def import_extraction_rules(session: AsyncSession, rules: list):
    """å¯¼å…¥æå–è§„åˆ™"""
    logger.info(f"ğŸ“¥ å¯¼å…¥ {len(rules)} æ¡æå–è§„åˆ™...")
    
    for rule in rules:
        db_rule = ExtractionRule(
            rule_name=rule['rule_name'],
            material_category=rule['material_category'],
            attribute_name=rule['attribute_name'],
            regex_pattern=rule['regex_pattern'],
            priority=rule.get('priority', 0),
            confidence=rule.get('confidence', 0.5),
            is_active=rule.get('is_active', True),
            description=rule.get('description', ''),
            example_input=rule.get('example_input', ''),
            example_output=rule.get('example_output', ''),
            created_by=rule.get('created_by', 'system')
        )
        session.add(db_rule)
    
    await session.commit()
    logger.info("âœ… æå–è§„åˆ™å¯¼å…¥å®Œæˆ")


async def import_synonyms(session: AsyncSession, synonym_dict: dict):
    """å¯¼å…¥åŒä¹‰è¯"""
    # å°†å­—å…¸è½¬æ¢ä¸ºè®°å½•åˆ—è¡¨
    synonym_records = []
    for standard_term, variants in synonym_dict.items():
        for variant in variants:
            if variant != standard_term:
                synonym_records.append({
                    'original_term': variant,
                    'standard_term': standard_term
                })
    
    logger.info(f"ğŸ“¥ å¯¼å…¥ {len(synonym_records)} æ¡åŒä¹‰è¯è®°å½•...")
    
    for record in synonym_records:
        db_synonym = Synonym(
            original_term=record['original_term'],
            standard_term=record['standard_term']
        )
        session.add(db_synonym)
    
    await session.commit()
    logger.info("âœ… åŒä¹‰è¯å¯¼å…¥å®Œæˆ")


async def import_category_keywords(session: AsyncSession, category_keywords: dict):
    """å¯¼å…¥åˆ†ç±»å…³é”®è¯"""
    logger.info(f"ğŸ“¥ å¯¼å…¥ {len(category_keywords)} ä¸ªåˆ†ç±»çš„å…³é”®è¯...")
    
    for category_name, keywords in category_keywords.items():
        if keywords:  # åªå¯¼å…¥æœ‰å…³é”®è¯çš„åˆ†ç±»
            db_category = KnowledgeCategory(
                category_name=category_name,
                keywords=keywords
            )
            session.add(db_category)
    
    await session.commit()
    logger.info("âœ… åˆ†ç±»å…³é”®è¯å¯¼å…¥å®Œæˆ")


async def verify_import(session: AsyncSession):
    """éªŒè¯å¯¼å…¥ç»“æœ"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ” éªŒè¯å¯¼å…¥ç»“æœ...")
    logger.info("=" * 80)
    
    # ç»Ÿè®¡å„è¡¨æ•°æ®é‡
    result = await session.execute(text("SELECT COUNT(*) FROM extraction_rules"))
    rules_count = result.scalar()
    
    result = await session.execute(text("SELECT COUNT(*) FROM synonyms"))
    synonyms_count = result.scalar()
    
    result = await session.execute(text("SELECT COUNT(*) FROM knowledge_categories"))
    categories_count = result.scalar()
    
    logger.info(f"âœ… æå–è§„åˆ™: {rules_count} æ¡")
    logger.info(f"âœ… åŒä¹‰è¯: {synonyms_count} æ¡")
    logger.info(f"âœ… åˆ†ç±»å…³é”®è¯: {categories_count} ä¸ªåˆ†ç±»")
    
    return rules_count > 0 and synonyms_count > 0 and categories_count > 0


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("ğŸš€ ä»PostgreSQLæ¸…æ´—åæ•°æ®ç”ŸæˆçŸ¥è¯†åº“å¹¶ç›´æ¥å¯¼å…¥")
    logger.info("=" * 80)
    
    # åˆ›å»ºPostgreSQLå¼•æ“
    engine = create_async_engine(
        database_config.database_url,
        echo=False,
        pool_pre_ping=True
    )
    
    async_session_maker = sessionmaker(
        engine,
        class_=AsyncSession,
        expire_on_commit=False
    )
    
    try:
        async with async_session_maker() as session:
            # æ­¥éª¤1: åŠ è½½æ•°æ®å¹¶ç”ŸæˆçŸ¥è¯†åº“
            logger.info("\nğŸ“Š æ­¥éª¤1: åŠ è½½æ¸…æ´—åçš„æ•°æ®...")
            generator = MaterialKnowledgeGenerator(pg_session=session)
            await generator.load_all_data()
            
            logger.info("\nğŸ”§ æ­¥éª¤2: ç”ŸæˆçŸ¥è¯†åº“...")
            extraction_rules = generator.generate_extraction_rules()
            synonyms = generator.generate_synonym_dictionary()
            category_keywords = generator.category_keywords
            
            logger.info(f"  âœ… ç”Ÿæˆ {len(extraction_rules)} æ¡æå–è§„åˆ™")
            logger.info(f"  âœ… ç”Ÿæˆ {len(synonyms)} ä¸ªåŒä¹‰è¯ç»„")
            logger.info(f"  âœ… ç”Ÿæˆ {len(category_keywords)} ä¸ªåˆ†ç±»å…³é”®è¯")
            
            # æ­¥éª¤2: æ¸…ç©ºç°æœ‰æ•°æ®
            logger.info("\nğŸ—‘ï¸  æ­¥éª¤3: æ¸…ç©ºç°æœ‰çŸ¥è¯†åº“æ•°æ®...")
            await clear_existing_data(session)
            
            # æ­¥éª¤3: å¯¼å…¥æ–°æ•°æ®
            logger.info("\nğŸ“¥ æ­¥éª¤4: å¯¼å…¥æ–°çŸ¥è¯†åº“åˆ°æ•°æ®åº“...")
            await import_extraction_rules(session, extraction_rules)
            await import_synonyms(session, synonyms)
            await import_category_keywords(session, category_keywords)
            
            # æ­¥éª¤4: éªŒè¯å¯¼å…¥
            success = await verify_import(session)
            
            if success:
                logger.info("\n" + "=" * 80)
                logger.info("âœ… çŸ¥è¯†åº“ç”Ÿæˆå¹¶å¯¼å…¥æˆåŠŸï¼")
                logger.info("=" * 80)
                logger.info("ğŸ’¡ æç¤º: åç«¯æœåŠ¡ä¼šåœ¨5ç§’åè‡ªåŠ¨åˆ·æ–°çŸ¥è¯†åº“ç¼“å­˜")
            else:
                logger.error("\nâŒ å¯¼å…¥éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®")
                
    except Exception as e:
        logger.error(f"\nâŒ æ“ä½œå¤±è´¥: {e}", exc_info=True)
        raise
    finally:
        await engine.dispose()


if __name__ == "__main__":
    asyncio.run(main())

