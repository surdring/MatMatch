"""
PostgreSQLè§„åˆ™å’Œè¯å…¸è‡ªåŠ¨å¯¼å…¥è„šæœ¬
åŸºäºç”Ÿæˆçš„æ ‡å‡†åŒ–è§„åˆ™å’Œè¯å…¸ï¼Œè‡ªåŠ¨å¯¼å…¥åˆ°PostgreSQLæ•°æ®åº“
"""

import json
import asyncio
import asyncpg
import logging
import os
from datetime import datetime
from typing import Dict, List

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class PostgreSQLImporter:
    """PostgreSQLè§„åˆ™å’Œè¯å…¸å¯¼å…¥å™¨"""
    
    def __init__(self):
        self.connection = None
        self.pg_config = {
            'host': os.getenv('PG_HOST', 'localhost'),
            'port': int(os.getenv('PG_PORT', 5432)),
            'database': os.getenv('PG_DATABASE', 'matmatch'),
            'user': os.getenv('PG_USERNAME', 'matmatch'),
            'password': os.getenv('PG_PASSWORD', 'matmatch')
        }
    
    async def connect(self):
        """è¿æ¥PostgreSQLæ•°æ®åº“"""
        try:
            self.connection = await asyncpg.connect(**self.pg_config)
            logger.info("âœ… PostgreSQLæ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ PostgreSQLè¿æ¥å¤±è´¥: {e}")
            return False
    
    async def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.connection:
            await self.connection.close()
            logger.info("ğŸ”Œ PostgreSQLè¿æ¥å·²æ–­å¼€")
    
    async def create_tables(self):
        """åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„"""
        logger.info("ğŸ—ï¸ åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„...")
        
        # åˆ›å»ºæå–è§„åˆ™è¡¨
        create_rules_table = """
        CREATE TABLE IF NOT EXISTS extraction_rules (
            id SERIAL PRIMARY KEY,
            rule_id VARCHAR(50) UNIQUE NOT NULL,
            rule_name VARCHAR(100) NOT NULL,
            material_category VARCHAR(100) NOT NULL,
            attribute_name VARCHAR(50) NOT NULL,
            regex_pattern TEXT NOT NULL,
            priority INTEGER DEFAULT 100,
            confidence DECIMAL(3,2) DEFAULT 1.0,
            is_active BOOLEAN DEFAULT TRUE,
            description TEXT,
            examples TEXT[],
            data_source VARCHAR(50) DEFAULT 'oracle_real_data',
            created_by VARCHAR(50) DEFAULT 'system',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """
        
        # åˆ›å»ºåŒä¹‰è¯è¡¨
        create_synonyms_table = """
        CREATE TABLE IF NOT EXISTS synonyms (
            id SERIAL PRIMARY KEY,
            original_term VARCHAR(200) NOT NULL,
            standard_term VARCHAR(200) NOT NULL,
            category VARCHAR(50) DEFAULT 'general',
            synonym_type VARCHAR(20) DEFAULT 'general',
            is_active BOOLEAN DEFAULT TRUE,
            confidence DECIMAL(3,2) DEFAULT 1.0,
            description TEXT,
            created_by VARCHAR(50) DEFAULT 'system',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """
        
        # åˆ›å»ºç‰©æ–™ç±»åˆ«è¡¨
        create_categories_table = """
        CREATE TABLE IF NOT EXISTS material_categories (
            id SERIAL PRIMARY KEY,
            category_name VARCHAR(200) NOT NULL,
            keywords TEXT[],
            detection_confidence DECIMAL(3,2) DEFAULT 0.8,
            category_type VARCHAR(50) DEFAULT 'general',
            priority INTEGER DEFAULT 50,
            is_active BOOLEAN DEFAULT TRUE,
            description TEXT,
            created_by VARCHAR(50) DEFAULT 'system',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """
        
        try:
            await self.connection.execute(create_rules_table)
            await self.connection.execute(create_synonyms_table)
            await self.connection.execute(create_categories_table)
            logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
            return False
    
    async def create_indexes(self):
        """åˆ›å»ºæ•°æ®åº“ç´¢å¼•"""
        logger.info("ğŸ” åˆ›å»ºæ•°æ®åº“ç´¢å¼•...")
        
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_extraction_rules_category ON extraction_rules (material_category, priority) WHERE is_active = TRUE;",
            "CREATE INDEX IF NOT EXISTS idx_extraction_rules_rule_id ON extraction_rules (rule_id) WHERE is_active = TRUE;",
            "CREATE INDEX IF NOT EXISTS idx_synonyms_original ON synonyms (original_term) WHERE is_active = TRUE;",
            "CREATE INDEX IF NOT EXISTS idx_synonyms_standard ON synonyms (standard_term) WHERE is_active = TRUE;",
            "CREATE INDEX IF NOT EXISTS idx_synonyms_category_type ON synonyms (category, synonym_type) WHERE is_active = TRUE;",
            "CREATE INDEX IF NOT EXISTS idx_categories_name ON material_categories (category_name) WHERE is_active = TRUE;",
            "CREATE INDEX IF NOT EXISTS idx_categories_keywords ON material_categories USING gin (keywords) WHERE is_active = TRUE;"
        ]
        
        for index_sql in indexes:
            try:
                await self.connection.execute(index_sql)
            except Exception as e:
                logger.warning(f"åˆ›å»ºç´¢å¼•æ—¶å‡ºç°è­¦å‘Š: {e}")
        
        logger.info("âœ… æ•°æ®åº“ç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    async def import_extraction_rules(self):
        """å¯¼å…¥æå–è§„åˆ™"""
        logger.info("ğŸ“¥ å¯¼å…¥æå–è§„åˆ™...")
        
        # æŸ¥æ‰¾æœ€æ–°çš„è§„åˆ™æ–‡ä»¶
        rules_files = [f for f in os.listdir('.') if f.startswith('standardized_extraction_rules_') and f.endswith('.json')]
        if not rules_files:
            logger.error("âŒ æœªæ‰¾åˆ°æ ‡å‡†åŒ–æå–è§„åˆ™æ–‡ä»¶")
            return False
        
        latest_rules_file = sorted(rules_files)[-1]
        logger.info(f"ğŸ“ ä½¿ç”¨è§„åˆ™æ–‡ä»¶: {latest_rules_file}")
        
        with open(latest_rules_file, 'r', encoding='utf-8') as f:
            rules = json.load(f)
        
        # æ¸…ç©ºç°æœ‰è§„åˆ™
        await self.connection.execute("DELETE FROM extraction_rules WHERE created_by = 'system'")
        
        # æ‰¹é‡æ’å…¥è§„åˆ™
        insert_query = """
        INSERT INTO extraction_rules 
        (rule_id, rule_name, material_category, attribute_name, regex_pattern, priority, 
         confidence, description, examples, data_source, created_by)
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, 'system')
        """
        
        for rule in rules:
            await self.connection.execute(
                insert_query,
                rule['id'],
                rule['name'],
                rule['category'],
                rule['attribute'],
                rule['pattern'],
                rule['priority'],
                rule['confidence'],
                rule.get('description', ''),
                rule.get('examples', []),
                rule.get('data_source', 'oracle_real_data')
            )
        
        logger.info(f"âœ… æˆåŠŸå¯¼å…¥ {len(rules)} æ¡æå–è§„åˆ™")
        return len(rules)
    
    async def import_synonym_dictionary(self):
        """å¯¼å…¥åŒä¹‰è¯å…¸"""
        logger.info("ğŸ“¥ å¯¼å…¥åŒä¹‰è¯å…¸...")
        
        # æŸ¥æ‰¾æœ€æ–°çš„è¯å…¸æ–‡ä»¶
        dict_files = [f for f in os.listdir('.') if f.startswith('standardized_synonym_dictionary_') and f.endswith('.json')]
        if not dict_files:
            logger.error("âŒ æœªæ‰¾åˆ°æ ‡å‡†åŒ–åŒä¹‰è¯å…¸æ–‡ä»¶")
            return False
        
        latest_dict_file = sorted(dict_files)[-1]
        logger.info(f"ğŸ“ ä½¿ç”¨è¯å…¸æ–‡ä»¶: {latest_dict_file}")
        
        with open(latest_dict_file, 'r', encoding='utf-8') as f:
            synonym_dict = json.load(f)
        
        # æ¸…ç©ºç°æœ‰åŒä¹‰è¯
        await self.connection.execute("DELETE FROM synonyms WHERE created_by = 'system'")
        
        # æ‰¹é‡æ’å…¥åŒä¹‰è¯
        insert_query = """
        INSERT INTO synonyms 
        (original_term, standard_term, category, synonym_type, created_by)
        VALUES ($1, $2, $3, $4, 'system')
        """
        
        total_synonyms = 0
        for standard_term, variants in synonym_dict.items():
            # ç¡®å®šåŒä¹‰è¯ç±»å‹å’Œç±»åˆ«
            synonym_type = self._detect_synonym_type(standard_term)
            category = self._detect_synonym_category(standard_term)
            
            for variant in variants:
                await self.connection.execute(
                    insert_query,
                    variant,
                    standard_term,
                    category,
                    synonym_type
                )
                total_synonyms += 1
        
        logger.info(f"âœ… æˆåŠŸå¯¼å…¥ {total_synonyms} æ¡åŒä¹‰è¯")
        return total_synonyms
    
    async def import_category_keywords(self):
        """å¯¼å…¥ç±»åˆ«å…³é”®è¯"""
        logger.info("ğŸ“¥ å¯¼å…¥ç±»åˆ«å…³é”®è¯...")
        
        # æŸ¥æ‰¾æœ€æ–°çš„å…³é”®è¯æ–‡ä»¶
        keywords_files = [f for f in os.listdir('.') if f.startswith('standardized_category_keywords_') and f.endswith('.json')]
        if not keywords_files:
            logger.error("âŒ æœªæ‰¾åˆ°æ ‡å‡†åŒ–ç±»åˆ«å…³é”®è¯æ–‡ä»¶")
            return False
        
        latest_keywords_file = sorted(keywords_files)[-1]
        logger.info(f"ğŸ“ ä½¿ç”¨å…³é”®è¯æ–‡ä»¶: {latest_keywords_file}")
        
        with open(latest_keywords_file, 'r', encoding='utf-8') as f:
            categories = json.load(f)
        
        # æ¸…ç©ºç°æœ‰ç±»åˆ«
        await self.connection.execute("DELETE FROM material_categories WHERE created_by = 'system'")
        
        # æ‰¹é‡æ’å…¥ç±»åˆ«
        insert_query = """
        INSERT INTO material_categories 
        (category_name, keywords, detection_confidence, category_type, priority, created_by)
        VALUES ($1, $2, $3, $4, $5, 'system')
        """
        
        for category_name, info in categories.items():
            await self.connection.execute(
                insert_query,
                category_name,
                info['keywords'],
                info['detection_confidence'],
                info['category_type'],
                info['priority']
            )
        
        logger.info(f"âœ… æˆåŠŸå¯¼å…¥ {len(categories)} ä¸ªç±»åˆ«å…³é”®è¯")
        return len(categories)
    
    def _detect_synonym_type(self, term: str) -> str:
        """æ£€æµ‹åŒä¹‰è¯ç±»å‹"""
        term_lower = term.lower()
        
        # æè´¨ç±»å‹
        materials = ['304', '316', 'ä¸é”ˆé’¢', 'ç¢³é’¢', 'åˆé‡‘é’¢', 'é“¸é“', 'é“œ', 'é“']
        if any(material in term_lower for material in materials):
            return 'material'
        
        # å•ä½ç±»å‹
        units = ['mm', 'kg', 'mpa', 'bar', 'ä¸ª', 'åª', 'ä»¶', 'å¥—']
        if any(unit in term_lower for unit in units):
            return 'unit'
        
        # è§„æ ¼ç±»å‹
        if any(spec in term for spec in ['x', 'Ã—', '*', 'DN', 'PN', 'Î¦']):
            return 'specification'
        
        return 'general'
    
    def _detect_synonym_category(self, term: str) -> str:
        """æ£€æµ‹åŒä¹‰è¯æ‰€å±ç±»åˆ«"""
        term_lower = term.lower()
        
        category_mapping = {
            'material': ['304', '316', 'ä¸é”ˆé’¢', 'ç¢³é’¢', 'åˆé‡‘é’¢', 'é“¸é“', 'é“œ', 'é“'],
            'unit': ['mm', 'kg', 'mpa', 'bar', 'ä¸ª', 'åª', 'ä»¶', 'å¥—'],
            'specification': ['x', 'Ã—', '*', 'DN', 'PN', 'Î¦'],
            'fastener': ['èºæ “', 'èºé’‰', 'M'],
            'valve': ['é˜€', 'valve', 'PN'],
            'pipe': ['ç®¡', 'pipe', 'DN']
        }
        
        for category, keywords in category_mapping.items():
            if any(keyword in term_lower for keyword in keywords):
                return category
        
        return 'general'
    
    async def verify_import(self):
        """éªŒè¯å¯¼å…¥ç»“æœ"""
        logger.info("ğŸ” éªŒè¯å¯¼å…¥ç»“æœ...")
        
        # æ£€æŸ¥å„è¡¨çš„è®°å½•æ•°
        rules_count = await self.connection.fetchval("SELECT COUNT(*) FROM extraction_rules WHERE is_active = TRUE")
        synonyms_count = await self.connection.fetchval("SELECT COUNT(*) FROM synonyms WHERE is_active = TRUE")
        categories_count = await self.connection.fetchval("SELECT COUNT(*) FROM material_categories WHERE is_active = TRUE")
        
        logger.info(f"ğŸ“Š å¯¼å…¥éªŒè¯ç»“æœ:")
        logger.info(f"  - æå–è§„åˆ™: {rules_count} æ¡")
        logger.info(f"  - åŒä¹‰è¯: {synonyms_count} æ¡")
        logger.info(f"  - ç±»åˆ«å…³é”®è¯: {categories_count} ä¸ª")
        
        # æµ‹è¯•è§„åˆ™
        test_result = await self.connection.fetch("""
            SELECT rule_name, confidence 
            FROM extraction_rules 
            WHERE is_active = TRUE 
            ORDER BY priority DESC 
            LIMIT 3
        """)
        
        logger.info("ğŸ§ª è§„åˆ™æµ‹è¯•:")
        for rule in test_result:
            logger.info(f"  - {rule['rule_name']}: ç½®ä¿¡åº¦ {rule['confidence']}")
        
        return {
            'rules_count': rules_count,
            'synonyms_count': synonyms_count,
            'categories_count': categories_count
        }


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹PostgreSQLè§„åˆ™å’Œè¯å…¸å¯¼å…¥")
    
    importer = PostgreSQLImporter()
    
    try:
        # è¿æ¥æ•°æ®åº“
        if not await importer.connect():
            return False
        
        # åˆ›å»ºè¡¨ç»“æ„
        if not await importer.create_tables():
            return False
        
        # å¯¼å…¥æ•°æ®
        rules_count = await importer.import_extraction_rules()
        synonyms_count = await importer.import_synonym_dictionary()
        categories_count = await importer.import_category_keywords()
        
        # åˆ›å»ºç´¢å¼•
        await importer.create_indexes()
        
        # éªŒè¯å¯¼å…¥
        result = await importer.verify_import()
        
        logger.info("ğŸ‰ PostgreSQLè§„åˆ™å’Œè¯å…¸å¯¼å…¥å®Œæˆï¼")
        logger.info(f"ğŸ“Š å¯¼å…¥ç»Ÿè®¡:")
        logger.info(f"  - æå–è§„åˆ™: {result['rules_count']} æ¡")
        logger.info(f"  - åŒä¹‰è¯: {result['synonyms_count']} æ¡")
        logger.info(f"  - ç±»åˆ«å…³é”®è¯: {result['categories_count']} ä¸ª")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ å¯¼å…¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False
    finally:
        await importer.disconnect()


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
