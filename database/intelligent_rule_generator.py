"""
æ™ºèƒ½è§„åˆ™å’ŒåŒä¹‰è¯å…¸ç”Ÿæˆå™¨
åŸºäºOracleæ•°æ®åº“ä¸­çš„çœŸå®ç‰©æ–™æ•°æ®ï¼Œè‡ªåŠ¨ç”Ÿæˆæå–è§„åˆ™å’ŒåŒä¹‰è¯å…¸
"""

import re
import json
import logging
from collections import defaultdict, Counter
from typing import Dict, List, Set, Tuple, Optional
from datetime import datetime
import pandas as pd

def normalize_text_comprehensive(text: str) -> str:
    """
    ç»¼åˆæ–‡æœ¬æ ‡å‡†åŒ–å¤„ç†ï¼šå¤§å°å†™æ ‡å‡†åŒ– + ç©ºæ ¼æ¸…ç†
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        
    Returns:
        æ ‡å‡†åŒ–åçš„æ–‡æœ¬
    """
    if not text:
        return text
    
    # 1. å»é™¤é¦–å°¾ç©ºæ ¼
    result = text.strip()
    
    # 2. å°†å¤šä¸ªè¿ç»­ç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    result = re.sub(r'\s+', ' ', result)
    
    # 3. æ ‡å‡†åŒ–å¸¸è§çš„å¤§å°å†™é—®é¢˜ï¼ˆä¿æŒå“ç‰Œåç­‰çš„æ­£ç¡®å¤§å°å†™ï¼‰
    # è¿™é‡Œä¸åšå…¨å±€å¤§å°å†™è½¬æ¢ï¼Œå› ä¸ºå“ç‰Œåç­‰éœ€è¦ä¿æŒåŸæœ‰å¤§å°å†™
    
    return result

def generate_case_variants(text: str) -> List[str]:
    """
    ç”Ÿæˆæ–‡æœ¬çš„å¤§å°å†™å˜ä½“
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        
    Returns:
        å¤§å°å†™å˜ä½“åˆ—è¡¨
    """
    if not text:
        return []
    
    variants = [text]  # åŸæ–‡æœ¬
    
    # å…¨å°å†™
    lower_text = text.lower()
    if lower_text != text:
        variants.append(lower_text)
    
    # å…¨å¤§å†™
    upper_text = text.upper()
    if upper_text != text:
        variants.append(upper_text)
    
    # é¦–å­—æ¯å¤§å†™
    title_text = text.title()
    if title_text != text and title_text not in variants:
        variants.append(title_text)
    
    return variants

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class IntelligentRuleGenerator:
    """æ™ºèƒ½è§„åˆ™å’ŒåŒä¹‰è¯å…¸ç”Ÿæˆå™¨"""
    
    def __init__(self, oracle_connector):
        self.oracle = oracle_connector
        self.materials_data = []
        self.categories_data = []
        self.units_data = []
        
        # é¢„å®šä¹‰çš„ç‰©æ–™ç±»åˆ«å…³é”®è¯
        self.category_keywords = {
            'bearing': ['è½´æ‰¿', 'è»¸æ‰¿', 'bearing', 'æ»šåŠ¨è½´æ‰¿', 'æ»‘åŠ¨è½´æ‰¿'],
            'bolt': ['èºæ “', 'èºé’‰', 'èºä¸', 'bolt', 'screw', 'å†…å…­è§’', 'å¤–å…­è§’', 'å¹³å¤´', 'æ²‰å¤´'],
            'valve': ['é˜€', 'é˜€é—¨', 'é–¥é–€', 'valve', 'çƒé˜€', 'é—¸é˜€', 'æˆªæ­¢é˜€', 'è¶é˜€', 'æ­¢å›é˜€'],
            'pipe': ['ç®¡', 'ç®¡é“', 'ç®¡ä»¶', 'pipe', 'tube', 'å¼¯å¤´', 'ä¸‰é€š', 'å››é€š', 'å¼‚å¾„ç®¡'],
            'electrical': ['æ¥è§¦å™¨', 'ç»§ç”µå™¨', 'æ–­è·¯å™¨', 'å˜é¢‘å™¨', 'contactor', 'relay', 'å¼€å…³', 'ç†”æ–­å™¨'],
            'pump': ['æ³µ', 'æ°´æ³µ', 'æ²¹æ³µ', 'pump', 'ç¦»å¿ƒæ³µ', 'é½¿è½®æ³µ', 'æŸ±å¡æ³µ'],
            'motor': ['ç”µæœº', 'é©¬è¾¾', 'ç”µåŠ¨æœº', 'motor', 'å¼‚æ­¥ç”µæœº', 'åŒæ­¥ç”µæœº', 'ä¼ºæœç”µæœº'],
            'sensor': ['ä¼ æ„Ÿå™¨', 'æ„Ÿåº”å™¨', 'sensor', 'å‹åŠ›ä¼ æ„Ÿå™¨', 'æ¸©åº¦ä¼ æ„Ÿå™¨', 'æµé‡ä¼ æ„Ÿå™¨'],
            'cable': ['ç”µç¼†', 'çº¿ç¼†', 'cable', 'wire', 'æ§åˆ¶ç”µç¼†', 'ç”µåŠ›ç”µç¼†', 'é€šä¿¡ç”µç¼†'],
            'filter': ['è¿‡æ»¤å™¨', 'æ»¤èŠ¯', 'filter', 'ç©ºæ°”æ»¤æ¸…å™¨', 'æœºæ²¹æ»¤æ¸…å™¨', 'æ¶²å‹æ»¤èŠ¯'],
            'seal': ['å¯†å°', 'å¯†å°ä»¶', 'seal', 'gasket', 'o-ring', 'å¯†å°åœˆ', 'å«ç‰‡'],
            'fastener': ['ç´§å›ºä»¶', 'fastener', 'å«åœˆ', 'æŒ¡åœˆ', 'é”€', 'é”®'],
            'tool': ['å·¥å…·', 'tool', 'åˆ€å…·', 'é‡å…·', 'å¤¹å…·', 'æ¨¡å…·'],
            'instrument': ['ä»ªè¡¨', 'ä»ªå™¨', 'instrument', 'gauge', 'å‹åŠ›è¡¨', 'æ¸©åº¦è¡¨', 'æµé‡è¡¨']
        }
    
    async def load_all_data(self):
        """åŠ è½½æ‰€æœ‰Oracleæ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹åŠ è½½Oracleæ•°æ®...")
        
        if not self.oracle.connect():
            raise Exception("Oracleæ•°æ®åº“è¿æ¥å¤±è´¥")
        
        try:
            # åŠ è½½ç‰©æ–™æ•°æ®
            from oracle_config import MaterialQueries
            logger.info("ğŸ“Š åŠ è½½ç‰©æ–™æ•°æ®...")
            self.materials_data = self.oracle.execute_query_batch(
                MaterialQueries.BASIC_MATERIAL_QUERY, 
                batch_size=5000
            )
            logger.info(f"âœ… å·²åŠ è½½ {len(self.materials_data)} æ¡ç‰©æ–™æ•°æ®")
            
            # åŠ è½½åˆ†ç±»æ•°æ®
            logger.info("ğŸ“‚ åŠ è½½åˆ†ç±»æ•°æ®...")
            self.categories_data = self.oracle.execute_query(
                MaterialQueries.MATERIAL_CATEGORIES_QUERY
            )
            logger.info(f"âœ… å·²åŠ è½½ {len(self.categories_data)} ä¸ªç‰©æ–™åˆ†ç±»")
            
            # åŠ è½½å•ä½æ•°æ®
            logger.info("ğŸ“ åŠ è½½è®¡é‡å•ä½æ•°æ®...")
            self.units_data = self.oracle.execute_query(
                MaterialQueries.UNIT_QUERY
            )
            logger.info(f"âœ… å·²åŠ è½½ {len(self.units_data)} ä¸ªè®¡é‡å•ä½")
            
        finally:
            self.oracle.disconnect()
    
    def generate_extraction_rules(self) -> List[Dict]:
        """åŸºäºçœŸå®æ•°æ®ç”Ÿæˆå±æ€§æå–è§„åˆ™"""
        logger.info("ğŸ”§ å¼€å§‹åŸºäºçœŸå®æ•°æ®ç”Ÿæˆå±æ€§æå–è§„åˆ™...")
        
        rules = []
        
        if not self.materials_data:
            logger.warning("âš ï¸ æ²¡æœ‰ç‰©æ–™æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆè§„åˆ™")
            return rules
        
        # åˆ†æç‰©æ–™æè¿°æ¨¡å¼
        patterns = self._analyze_description_patterns()
        
        # 1. åŸºäºæ•°æ®åˆ†æç”Ÿæˆé€šç”¨è§„åˆ™
        general_rules = self._generate_general_rules_from_data()
        rules.extend(general_rules)
        
        # 2. åŸºäºåˆ†ç±»æ•°æ®ç”Ÿæˆç±»åˆ«ç‰¹å®šè§„åˆ™
        category_rules = self._generate_category_specific_rules()
        rules.extend(category_rules)
        
        # 3. åŸºäºç‰©æ–™æ•°æ®ç”Ÿæˆå“ç‰Œæå–è§„åˆ™
        brand_rules = self._generate_brand_rules()
        rules.extend(brand_rules)
        
        # 4. åŸºäºç‰©æ–™æ•°æ®ç”Ÿæˆæè´¨æå–è§„åˆ™
        material_rules = self._generate_material_rules()
        rules.extend(material_rules)
        
        logger.info(f"âœ… åŸºäºçœŸå®æ•°æ®ç”Ÿæˆäº† {len(rules)} æ¡å±æ€§æå–è§„åˆ™")
        return rules
    
    def generate_synonym_dictionary(self) -> Dict[str, List[str]]:
        """åŸºäºçœŸå®æ•°æ®ç”ŸæˆåŒä¹‰è¯å…¸"""
        logger.info("ğŸ“š å¼€å§‹åŸºäºçœŸå®æ•°æ®ç”ŸæˆåŒä¹‰è¯å…¸...")
        
        synonym_dict = {}
        
        if not self.materials_data:
            logger.warning("âš ï¸ æ²¡æœ‰ç‰©æ–™æ•°æ®ï¼Œæ— æ³•ç”ŸæˆåŒä¹‰è¯å…¸")
            return synonym_dict
        
        # 1. åŸºäºç‰©æ–™åç§°åˆ†æç”ŸæˆåŒä¹‰è¯
        name_variations = self._analyze_name_variations()
        synonym_dict.update(name_variations)
        
        # 2. åŸºäºå•ä½æ•°æ®ç”Ÿæˆå•ä½åŒä¹‰è¯
        unit_synonyms = self._generate_unit_synonyms()
        synonym_dict.update(unit_synonyms)
        
        # 3. åŸºäºè§„æ ¼æ•°æ®ç”Ÿæˆè§„æ ¼è¡¨ç¤ºåŒä¹‰è¯
        spec_synonyms = self._analyze_spec_variations()
        synonym_dict.update(spec_synonyms)
        
        # 4. åŸºäºå“ç‰Œæ•°æ®ç”Ÿæˆå“ç‰ŒåŒä¹‰è¯
        brand_synonyms = self._generate_brand_synonyms()
        synonym_dict.update(brand_synonyms)
        
        # 5. åŸºäºæè´¨æ•°æ®ç”Ÿæˆæè´¨åŒä¹‰è¯
        material_synonyms = self._generate_material_synonyms()
        synonym_dict.update(material_synonyms)
        
        logger.info(f"âœ… åŸºäºçœŸå®æ•°æ®ç”Ÿæˆäº† {len(synonym_dict)} ä¸ªåŒä¹‰è¯ç»„")
        return synonym_dict
    
    def _analyze_description_patterns(self) -> Dict[str, List[str]]:
        """åˆ†æç‰©æ–™æè¿°ä¸­çš„å¸¸è§æ¨¡å¼"""
        patterns = defaultdict(list)
        
        for material in self.materials_data:
            name = material.get('MATERIAL_NAME', '')
            spec = material.get('SPECIFICATION', '')
            model = material.get('MODEL', '')
            
            # åˆ†æå®Œæ•´æè¿°
            full_desc = f"{name} {spec} {model}".strip()
            
            # æå–æ•°å­—+å­—æ¯çš„æ¨¡å¼ï¼ˆå¯èƒ½æ˜¯å‹å·ï¼‰
            model_patterns = re.findall(r'\b[A-Z0-9]{3,}(?:-[A-Z0-9]+)?\b', full_desc.upper())
            patterns['models'].extend(model_patterns)
            
            # æå–å°ºå¯¸æ¨¡å¼
            size_patterns = re.findall(r'\b\d+(?:\.\d+)?[Ã—*xX]\d+(?:\.\d+)?(?:[Ã—*xX]\d+(?:\.\d+)?)?\b', full_desc)
            patterns['sizes'].extend(size_patterns)
            
            # æå–æè´¨æ¨¡å¼
            material_patterns = re.findall(r'\b(304|316L?|201|430|ä¸é”ˆé’¢|ç¢³é’¢|åˆé‡‘é’¢|é“¸é“|é“œ|é“)\b', full_desc)
            patterns['materials'].extend(material_patterns)
        
        return dict(patterns)
    
    def _analyze_name_variations(self) -> Dict[str, List[str]]:
        """åˆ†æç‰©æ–™åç§°å˜ä½“ï¼ˆåŒ…å«å¤§å°å†™å’Œç©ºæ ¼æ ‡å‡†åŒ–ï¼‰"""
        variations = {}
        
        # æŒ‰ç›¸ä¼¼åç§°åˆ†ç»„
        name_groups = defaultdict(list)
        
        for material in self.materials_data:
            name = normalize_text_comprehensive(material.get('MATERIAL_NAME', ''))
            short_name = normalize_text_comprehensive(material.get('SHORT_NAME', ''))
            english_name = normalize_text_comprehensive(material.get('ENGLISH_NAME', ''))
            
            if name:
                # æå–æ ¸å¿ƒå…³é”®è¯
                core_keywords = self._extract_core_keywords(name)
                for keyword in core_keywords:
                    # æ·»åŠ åŸå§‹åç§°åŠå…¶å¤§å°å†™å˜ä½“
                    name_variants = generate_case_variants(name)
                    name_groups[keyword].extend(name_variants)
                    
                    if short_name and short_name != name:
                        short_variants = generate_case_variants(short_name)
                        name_groups[keyword].extend(short_variants)
                    
                    if english_name:
                        english_variants = generate_case_variants(english_name)
                        name_groups[keyword].extend(english_variants)
        
        # ç”ŸæˆåŒä¹‰è¯ç»„
        for keyword, names in name_groups.items():
            if len(names) > 1:
                unique_names = list(set(names))
                if len(unique_names) > 1:
                    # é€‰æ‹©æœ€å¸¸è§çš„å½¢å¼ä½œä¸ºæ ‡å‡†å½¢å¼
                    standard_name = max(unique_names, key=len)  # é€‰æ‹©æœ€é•¿çš„ä½œä¸ºæ ‡å‡†
                    variants = [n for n in unique_names if n != standard_name]
                    if variants:
                        variations[standard_name] = variants
        
        return variations
    
    def _generate_unit_synonyms(self) -> Dict[str, List[str]]:
        """åŸºäºbd_measdocç”Ÿæˆå•ä½åŒä¹‰è¯ï¼ˆåŒ…å«å¤§å°å†™å˜ä½“ï¼‰"""
        unit_synonyms = {}
        
        for unit in self.units_data:
            unit_name = normalize_text_comprehensive(unit.get('UNIT_NAME', ''))
            english_name = normalize_text_comprehensive(unit.get('ENGLISH_NAME', ''))
            unit_code = normalize_text_comprehensive(unit.get('UNIT_CODE', ''))
            
            if unit_name:
                synonyms = []
                
                # æ·»åŠ å•ä½åç§°çš„å¤§å°å†™å˜ä½“
                synonyms.extend(generate_case_variants(unit_name))
                
                if english_name and english_name != unit_name:
                    synonyms.extend(generate_case_variants(english_name))
                
                if unit_code and unit_code != unit_name:
                    synonyms.extend(generate_case_variants(unit_code))
                
                # å»é‡å¹¶è¿‡æ»¤æ‰æ ‡å‡†åç§°æœ¬èº«
                unique_synonyms = list(set(synonyms))
                variants = [s for s in unique_synonyms if s != unit_name]
                
                if variants:
                    unit_synonyms[unit_name] = variants
        
        return unit_synonyms
    
    def _analyze_data_variations(self) -> Dict[str, List[str]]:
        """åŸºäºçœŸå®æ•°æ®åˆ†æå˜ä½“"""
        variations = {}
        
        # åˆ†æè§„æ ¼è¡¨ç¤ºçš„å˜ä½“
        spec_variations = defaultdict(set)
        
        for material in self.materials_data:
            spec = material.get('SPECIFICATION', '')
            if spec:
                # æŸ¥æ‰¾å°ºå¯¸è§„æ ¼çš„ä¸åŒè¡¨ç¤ºæ–¹æ³•
                size_matches = re.findall(r'\d+(?:\.\d+)?[Ã—*xX]\d+(?:\.\d+)?', spec)
                for match in size_matches:
                    # æ ‡å‡†åŒ–ä¸ºxæ ¼å¼
                    normalized = re.sub(r'[Ã—*X]', 'x', match)
                    spec_variations[normalized].add(match)
        
        # ç”Ÿæˆè§„æ ¼å˜ä½“åŒä¹‰è¯
        for normalized, variants in spec_variations.items():
            if len(variants) > 1:
                variations[normalized] = list(variants - {normalized})
        
        return variations
    
    def _analyze_spec_variations(self) -> Dict[str, List[str]]:
        """åˆ†æè§„æ ¼è¡¨ç¤ºçš„å˜ä½“ï¼ˆåŒ…å«æ ‡å‡†åŒ–å¤„ç†ï¼‰"""
        return self._analyze_data_variations()
    
    def _generate_brand_synonyms(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆå“ç‰ŒåŒä¹‰è¯ï¼ˆåŒ…å«å¤§å°å†™å˜ä½“ï¼‰"""
        brand_synonyms = {}
        
        # ä»ç‰©æ–™æ•°æ®ä¸­æå–å“ç‰Œä¿¡æ¯
        brand_patterns = defaultdict(int)
        
        for material in self.materials_data:
            name = normalize_text_comprehensive(material.get('MATERIAL_NAME', ''))
            # æå–å¯èƒ½çš„å“ç‰Œåï¼ˆé€šå¸¸æ˜¯å¤§å†™å­—æ¯ç»„åˆï¼‰
            brands = re.findall(r'\b[A-Z]{2,}\b', name)
            for brand in brands:
                brand_patterns[brand] += 1
        
        # ä¸ºå¸¸è§å“ç‰Œç”Ÿæˆå¤§å°å†™å˜ä½“
        common_brands = [brand for brand, count in brand_patterns.items() if count >= 5]
        
        for brand in common_brands:
            variants = generate_case_variants(brand)
            if len(variants) > 1:
                brand_synonyms[brand] = [v for v in variants if v != brand]
        
        return brand_synonyms
    
    def _generate_material_synonyms(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆæè´¨åŒä¹‰è¯ï¼ˆåŒ…å«å¤§å°å†™å˜ä½“ï¼‰"""
        material_synonyms = {}
        
        # å¸¸è§æè´¨åŠå…¶å˜ä½“
        common_materials = {
            'ä¸é”ˆé’¢': ['304', '316', '316L', 'SS', 'stainless steel'],
            'ç¢³é’¢': ['CS', 'carbon steel', 'A105'],
            'åˆé‡‘é’¢': ['alloy steel', '40Cr', '42CrMo'],
            'é“¸é“': ['cast iron', 'CI', 'HT200', 'HT250'],
            'é“œ': ['Cu', 'copper', 'brass'],
            'é“': ['Al', 'aluminum', 'aluminium']
        }
        
        for standard, variants in common_materials.items():
            all_variants = []
            for variant in variants:
                all_variants.extend(generate_case_variants(variant))
            
            # å»é‡
            unique_variants = list(set(all_variants))
            if unique_variants:
                material_synonyms[standard] = unique_variants
        
        return material_synonyms
    
    def _generate_general_rules_from_data(self) -> List[Dict]:
        """åŸºäºæ•°æ®åˆ†æç”Ÿæˆé€šç”¨è§„åˆ™"""
        rules = []
        
        # åŸºäºç‰©æ–™æè¿°æ¨¡å¼ç”Ÿæˆè§„åˆ™
        patterns = self._analyze_description_patterns()
        
        # ç”Ÿæˆå°ºå¯¸è§„æ ¼æå–è§„åˆ™
        if patterns.get('sizes'):
            rules.append({
                'rule_name': 'å°ºå¯¸è§„æ ¼æå–',
                'material_category': 'general',
                'attribute_name': 'size_specification',
                'regex_pattern': r'(\d+(?:\.\d+)?[Ã—*xX]\d+(?:\.\d+)?(?:[Ã—*xX]\d+(?:\.\d+)?)?)',
                'priority': 90,
                'description': 'æå–å°ºå¯¸è§„æ ¼å¦‚20x30, 50Ã—100ç­‰',
                'example_input': 'ä¸é”ˆé’¢ç®¡ 50Ã—100Ã—2',
                'example_output': '50Ã—100Ã—2'
            })
        
        return rules
    
    def _generate_category_specific_rules(self) -> List[Dict]:
        """ç”Ÿæˆç±»åˆ«ç‰¹å®šè§„åˆ™"""
        rules = []
        
        # èºçº¹è§„æ ¼æå–è§„åˆ™
        rules.append({
            'rule_name': 'èºçº¹è§„æ ¼æå–',
            'material_category': 'fastener',
            'attribute_name': 'thread_specification',
            'regex_pattern': r'(M\d+(?:\.\d+)?[Ã—*xX]\d+(?:\.\d+)?)',
            'priority': 95,
            'description': 'æå–èºçº¹è§„æ ¼å¦‚M8Ã—1.25',
            'example_input': 'å†…å…­è§’èºæ “ M8Ã—1.25Ã—20',
            'example_output': 'M8Ã—1.25'
        })
        
        return rules
    
    def _generate_brand_rules(self) -> List[Dict]:
        """ç”Ÿæˆå“ç‰Œæå–è§„åˆ™"""
        rules = []
        
        # ä»æ•°æ®ä¸­æå–å¸¸è§å“ç‰Œ
        brand_patterns = defaultdict(int)
        for material in self.materials_data:
            name = material.get('MATERIAL_NAME', '')
            brands = re.findall(r'\b[A-Z]{2,}\b', name)
            for brand in brands:
                brand_patterns[brand] += 1
        
        common_brands = [brand for brand, count in brand_patterns.items() if count >= 10]
        
        if common_brands:
            brand_regex = '|'.join(re.escape(brand) for brand in common_brands)
            rules.append({
                'rule_name': 'å“ç‰Œåç§°æå–',
                'material_category': 'general',
                'attribute_name': 'brand_name',
                'regex_pattern': f'\\b({brand_regex})\\b',
                'priority': 85,
                'description': f'æå–å“ç‰Œåç§°ï¼Œæ”¯æŒ{len(common_brands)}ä¸ªå¸¸è§å“ç‰Œ',
                'example_input': 'SKFæ·±æ²Ÿçƒè½´æ‰¿ 6206',
                'example_output': 'SKF'
            })
        
        return rules
    
    def _generate_material_rules(self) -> List[Dict]:
        """ç”Ÿæˆæè´¨æå–è§„åˆ™"""
        rules = []
        
        # æè´¨æå–è§„åˆ™
        rules.append({
            'rule_name': 'æè´¨ç±»å‹æå–',
            'material_category': 'general',
            'attribute_name': 'material_type',
            'regex_pattern': r'(304|316L?|201|430|ä¸é”ˆé’¢|ç¢³é’¢|åˆé‡‘é’¢|é“¸é“|é“œ|é“)',
            'priority': 88,
            'description': 'æå–æè´¨ç±»å‹',
            'example_input': '304ä¸é”ˆé’¢ç®¡',
            'example_output': '304'
        })
        
        return rules
    
    def _extract_core_keywords(self, text: str) -> List[str]:
        """æå–æ–‡æœ¬ä¸­çš„æ ¸å¿ƒå…³é”®è¯"""
        # å»é™¤å¸¸è§çš„ä¿®é¥°è¯
        stop_words = {'çš„', 'ç”¨', 'å‹', 'å¼', 'ç§', 'ä¸ª', 'åª', 'ä»¶', 'å¥—', 'æ ¹', 'æ¡', 'ç‰‡'}
        
        # åˆ†è¯ï¼ˆç®€å•çš„åŸºäºç©ºæ ¼å’Œæ ‡ç‚¹çš„åˆ†è¯ï¼‰
        words = re.findall(r'[\u4e00-\u9fff]+|[A-Za-z0-9]+', text)
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        keywords = [word for word in words if len(word) >= 2 and word not in stop_words]
        
        return keywords
    
    def detect_material_category(self, description: str) -> Tuple[str, float]:
        """æ£€æµ‹ç‰©æ–™ç±»åˆ«"""
        description_lower = description.lower()
        category_scores = {}
        
        for category, keywords in self.category_keywords.items():
            score = sum(1 for keyword in keywords if keyword in description_lower)
            if score > 0:
                category_scores[category] = score / len(keywords)
        
        if category_scores:
            best_category = max(category_scores, key=category_scores.get)
            confidence = category_scores[best_category]
            return best_category, confidence
        
        return 'general', 0.1
    
    def generate_category_statistics(self) -> Dict[str, any]:
        """ç”Ÿæˆç±»åˆ«ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("ğŸ“ˆ ç”Ÿæˆç±»åˆ«ç»Ÿè®¡ä¿¡æ¯...")
        
        category_stats = defaultdict(int)
        detection_results = []
        
        for material in self.materials_data:
            name = material.get('MATERIAL_NAME', '')
            spec = material.get('SPECIFICATION', '')
            model = material.get('MODEL', '')
            
            full_desc = f"{name} {spec} {model}".strip()
            category, confidence = self.detect_material_category(full_desc)
            
            category_stats[category] += 1
            detection_results.append({
                'erp_code': material.get('ERP_CODE'),
                'description': full_desc,
                'detected_category': category,
                'confidence': confidence
            })
        
        return {
            'category_distribution': dict(category_stats),
            'total_materials': len(self.materials_data),
            'detection_results': detection_results,
            'coverage_rate': len([r for r in detection_results if r['confidence'] > 0.3]) / len(detection_results)
        }
    
    def save_rules_and_dictionary(self, output_dir: str = './output'):
        """ä¿å­˜ç”Ÿæˆçš„è§„åˆ™å’Œè¯å…¸"""
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ç”Ÿæˆå¹¶ä¿å­˜æå–è§„åˆ™
        rules = self.generate_extraction_rules()
        rules_file = f"{output_dir}/extraction_rules_{timestamp}.json"
        with open(rules_file, 'w', encoding='utf-8') as f:
            json.dump(rules, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ æå–è§„åˆ™å·²ä¿å­˜åˆ°: {rules_file}")
        
        # ç”Ÿæˆå¹¶ä¿å­˜åŒä¹‰è¯å…¸
        synonyms = self.generate_synonym_dictionary()
        dict_file = f"{output_dir}/synonym_dictionary_{timestamp}.json"
        with open(dict_file, 'w', encoding='utf-8') as f:
            json.dump(synonyms, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ åŒä¹‰è¯å…¸å·²ä¿å­˜åˆ°: {dict_file}")
        
        # ç”Ÿæˆå¹¶ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
        stats = self.generate_category_statistics()
        stats_file = f"{output_dir}/category_statistics_{timestamp}.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {stats_file}")
        
        # ç”Ÿæˆå¯è¯»çš„è§„åˆ™æ–‡æ¡£
        self._generate_rules_documentation(rules, f"{output_dir}/rules_documentation_{timestamp}.md")
        
        return {
            'rules_file': rules_file,
            'dictionary_file': dict_file,
            'statistics_file': stats_file,
            'total_rules': len(rules),
            'total_synonyms': len(synonyms),
            'total_materials_analyzed': len(self.materials_data)
        }
    
    def _generate_rules_documentation(self, rules: List[Dict], output_file: str):
        """ç”Ÿæˆè§„åˆ™æ–‡æ¡£"""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# ç‰©æ–™å±æ€§æå–è§„åˆ™æ–‡æ¡£\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**æ•°æ®æ¥æº:** Oracle ERPç³»ç»Ÿ\n")
            f.write(f"**è§„åˆ™æ€»æ•°:** {len(rules)}\n\n")
            
            # æŒ‰ç±»åˆ«åˆ†ç»„
            category_rules = defaultdict(list)
            for rule in rules:
                category_rules[rule['material_category']].append(rule)
            
            for category, cat_rules in category_rules.items():
                f.write(f"## {category.upper()} ç±»åˆ«è§„åˆ™\n\n")
                
                for rule in sorted(cat_rules, key=lambda x: x['priority'], reverse=True):
                    f.write(f"### {rule['rule_name']}\n")
                    f.write(f"- **å±æ€§åç§°:** {rule['attribute_name']}\n")
                    f.write(f"- **æ­£åˆ™è¡¨è¾¾å¼:** `{rule['regex_pattern']}`\n")
                    f.write(f"- **ä¼˜å…ˆçº§:** {rule['priority']}\n")
                    f.write(f"- **æè¿°:** {rule['description']}\n")
                    if rule.get('example_input'):
                        f.write(f"- **ç¤ºä¾‹è¾“å…¥:** {rule['example_input']}\n")
                        f.write(f"- **ç¤ºä¾‹è¾“å‡º:** {rule['example_output']}\n")
                    f.write("\n")


async def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œè§„åˆ™å’Œè¯å…¸ç”Ÿæˆ"""
    logger.info("ğŸš€ å¯åŠ¨æ™ºèƒ½è§„åˆ™å’ŒåŒä¹‰è¯å…¸ç”Ÿæˆå™¨")
    
    # å¯¼å…¥Oracleè¿æ¥å™¨
    from oracledb_connector import OracleDBConnector
    from oracle_config import OracleConfig
    
    # åˆ›å»ºè¿æ¥å™¨
    connector = OracleDBConnector(**OracleConfig.get_connection_params())
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = IntelligentRuleGenerator(connector)
    
    try:
        # åŠ è½½æ•°æ®
        await generator.load_all_data()
        
        # ç”Ÿæˆå¹¶ä¿å­˜è§„åˆ™å’Œè¯å…¸
        result = generator.save_rules_and_dictionary()
        
        logger.info("ğŸ‰ ç”Ÿæˆå®Œæˆï¼")
        logger.info(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        logger.info(f"  - åˆ†æç‰©æ–™æ•°é‡: {result['total_materials_analyzed']}")
        logger.info(f"  - ç”Ÿæˆè§„åˆ™æ•°é‡: {result['total_rules']}")
        logger.info(f"  - ç”ŸæˆåŒä¹‰è¯ç»„: {result['total_synonyms']}")
        logger.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        logger.info(f"  - æå–è§„åˆ™: {result['rules_file']}")
        logger.info(f"  - åŒä¹‰è¯å…¸: {result['dictionary_file']}")
        logger.info(f"  - ç»Ÿè®¡æŠ¥å‘Š: {result['statistics_file']}")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
