"""
æ–‡ä»¶æ¸…å•å·¥å…·
æ˜¾ç¤ºdatabaseç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„çŠ¶æ€å’Œç”¨é€”
"""

import os
import json
from datetime import datetime
from pathlib import Path

def get_file_info():
    """è·å–æ–‡ä»¶ä¿¡æ¯"""
    current_dir = Path('.')
    files_info = []
    
    # å®šä¹‰æ–‡ä»¶ç±»åˆ«å’Œæè¿°
    file_descriptions = {
        # æ ¸å¿ƒæ‰§è¡Œè„šæœ¬
        'analyze_real_data.py': ('ğŸ” æ ¸å¿ƒè„šæœ¬', 'åˆ†æOracleçœŸå®æ•°æ®', 'å¿…é¡»é¦–æ¬¡æ‰§è¡Œ'),
        'generate_standardized_rules.py': ('ğŸ“Š æ ¸å¿ƒè„šæœ¬', 'ç”Ÿæˆæ ‡å‡†åŒ–è§„åˆ™å’Œè¯å…¸', 'æ ¸å¿ƒç”Ÿæˆå·¥å…·'),
        'generate_sql_import_script.py': ('ğŸ—„ï¸ æ ¸å¿ƒè„šæœ¬', 'ç”ŸæˆPostgreSQLå¯¼å…¥è„šæœ¬', 'æ¨èå¯¼å…¥æ–¹å¼'),
        'import_to_postgresql.py': ('ğŸš€ æ ¸å¿ƒè„šæœ¬', 'Pythonæ–¹å¼å¯¼å…¥PostgreSQL', 'Pythonç¯å¢ƒå¯¼å…¥'),
        'test_generated_rules.py': ('ğŸ§ª æ ¸å¿ƒè„šæœ¬', 'æµ‹è¯•è§„åˆ™æ•ˆæœ', 'éªŒè¯ç”Ÿæˆè´¨é‡'),
        
        # é…ç½®å’Œè¿æ¥æ–‡ä»¶
        'oracle_config.py': ('âš™ï¸ é…ç½®æ–‡ä»¶', 'Oracleæ•°æ®åº“é…ç½®', 'è¿æ¥å‚æ•°ã€SQLæŸ¥è¯¢'),
        'oracledb_connector.py': ('âš™ï¸ é…ç½®æ–‡ä»¶', 'Oracleæ•°æ®åº“è¿æ¥å™¨', 'è¿æ¥ã€æŸ¥è¯¢æ–¹æ³•'),
        'test_oracle_connection.py': ('âš™ï¸ é…ç½®æ–‡ä»¶', 'Oracleè¿æ¥æµ‹è¯•', 'è¿æ¥éªŒè¯'),
        
        # è¾…åŠ©å·¥å…·
        'check_oracle_tables.py': ('ğŸ” è¾…åŠ©å·¥å…·', 'æ£€æŸ¥Oracleè¡¨ç»“æ„', 'è°ƒè¯•è¿æ¥é—®é¢˜'),
        'check_material_fields.py': ('ğŸ” è¾…åŠ©å·¥å…·', 'æ£€æŸ¥ç‰©æ–™è¡¨å­—æ®µ', 'éªŒè¯è¡¨ç»“æ„'),
        'quick_import.bat': ('ğŸ” è¾…åŠ©å·¥å…·', 'Windowså¿«é€Ÿå¯¼å…¥', 'Windowsä¸€é”®å¯¼å…¥'),
        
        # æ—§ç‰ˆæœ¬/å¤‡ç”¨è„šæœ¬
        'generate_rules_and_dictionary.py': ('ğŸ”„ æ—§ç‰ˆè„šæœ¬', 'æ—§ç‰ˆè§„åˆ™ç”Ÿæˆå™¨', 'å·²è¢«æ›¿ä»£'),
        'intelligent_rule_generator.py': ('ğŸ“š å‚è€ƒè„šæœ¬', 'æ™ºèƒ½è§„åˆ™ç”Ÿæˆå™¨æ ¸å¿ƒ', 'é«˜çº§å®šåˆ¶å‚è€ƒ'),
        'init_postgresql_rules.py': ('ğŸ”„ æ—§ç‰ˆè„šæœ¬', 'æ—§ç‰ˆPostgreSQLåˆå§‹åŒ–', 'å·²è¢«æ›¿ä»£'),
        'one_click_setup.py': ('ğŸ”„ æ—§ç‰ˆè„šæœ¬', 'ä¸€é”®è®¾ç½®è„šæœ¬', 'å·²è¢«æ›¿ä»£'),
        
        # æ–‡æ¡£å’ŒæŒ‡å—
        'README.md': ('ğŸ“„ æ–‡æ¡£', 'ä¸»è¦ä½¿ç”¨æŒ‡å—', 'å®Œæ•´æ“ä½œæµç¨‹'),
        'postgresql_import_guide.md': ('ğŸ“„ æ–‡æ¡£', 'PostgreSQLå¯¼å…¥æŒ‡å—', 'è¯¦ç»†å¯¼å…¥æ­¥éª¤'),
        'åŒä¹‰è¯è¯å…¸æ„å»ºæ“ä½œæŒ‡å—.md': ('ğŸ“„ æ–‡æ¡£', 'åŒä¹‰è¯è¯å…¸æŒ‡å—', 'è¯å…¸æ„å»ºæ–¹æ³•'),
        'requirements.txt': ('ğŸ“„ é…ç½®', 'Pythonä¾èµ–æ¸…å•', 'é¡¹ç›®ä¾èµ–åŒ…'),
    }
    
    for file_path in current_dir.iterdir():
        if file_path.is_file() and not file_path.name.startswith('.') and file_path.name != '__pycache__':
            file_name = file_path.name
            file_size = file_path.stat().st_size
            file_mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
            
            # è·å–æ–‡ä»¶æè¿°
            if file_name in file_descriptions:
                category, description, usage = file_descriptions[file_name]
            elif file_name.startswith('oracle_data_analysis_'):
                category, description, usage = ('ğŸ“Š æ•°æ®æ–‡ä»¶', 'Oracleæ•°æ®åˆ†æç»“æœ', 'åˆ†æç»“æœJSON')
            elif file_name.startswith('oracle_data_analysis_report_'):
                category, description, usage = ('ğŸ“Š æ•°æ®æ–‡ä»¶', 'Oracleæ•°æ®åˆ†ææŠ¥å‘Š', 'å¯è¯»åˆ†ææŠ¥å‘Š')
            elif file_name.startswith('standardized_extraction_rules_'):
                category, description, usage = ('ğŸ“Š æ•°æ®æ–‡ä»¶', 'æ ‡å‡†åŒ–æå–è§„åˆ™', '6æ¡é«˜è´¨é‡è§„åˆ™')
            elif file_name.startswith('standardized_synonym_dictionary_'):
                category, description, usage = ('ğŸ“Š æ•°æ®æ–‡ä»¶', 'æ ‡å‡†åŒ–åŒä¹‰è¯å…¸', '3,347ä¸ªåŒä¹‰è¯')
            elif file_name.startswith('standardized_category_keywords_'):
                category, description, usage = ('ğŸ“Š æ•°æ®æ–‡ä»¶', 'æ ‡å‡†åŒ–ç±»åˆ«å…³é”®è¯', '1,243ä¸ªç±»åˆ«')
            elif file_name.startswith('standardized_rules_usage_'):
                category, description, usage = ('ğŸ“„ æ–‡æ¡£', 'æ ‡å‡†åŒ–è§„åˆ™ä½¿ç”¨è¯´æ˜', 'è§„åˆ™ä½¿ç”¨æ–‡æ¡£')
            elif file_name.startswith('postgresql_import_') and file_name.endswith('.sql'):
                category, description, usage = ('ğŸ—„ï¸ SQLæ–‡ä»¶', 'PostgreSQLå¯¼å…¥è„šæœ¬', '4,596æ¡SQLè¯­å¥')
            elif file_name.startswith('postgresql_import_usage_'):
                category, description, usage = ('ğŸ“„ æ–‡æ¡£', 'PostgreSQLå¯¼å…¥è¯´æ˜', 'å¯¼å…¥ä½¿ç”¨æ–‡æ¡£')
            else:
                category, description, usage = ('â“ å…¶ä»–', 'æœªåˆ†ç±»æ–‡ä»¶', 'éœ€è¦æ£€æŸ¥')
            
            files_info.append({
                'name': file_name,
                'category': category,
                'description': description,
                'usage': usage,
                'size': file_size,
                'size_mb': round(file_size / 1024 / 1024, 2) if file_size > 1024*1024 else round(file_size / 1024, 2),
                'size_unit': 'MB' if file_size > 1024*1024 else 'KB',
                'modified': file_mtime.strftime('%Y-%m-%d %H:%M:%S')
            })
    
    return sorted(files_info, key=lambda x: (x['category'], x['name']))

def print_file_summary():
    """æ‰“å°æ–‡ä»¶æ‘˜è¦"""
    files_info = get_file_info()
    
    print("=" * 80)
    print("ğŸ“ æ™ºèƒ½ç‰©æ–™æŸ¥é‡å·¥å…· - Databaseç›®å½•æ–‡ä»¶æ¸…å•")
    print("=" * 80)
    print(f"ğŸ“Š ç»Ÿè®¡æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‚ æ€»æ–‡ä»¶æ•°: {len(files_info)}")
    print()
    
    # æŒ‰ç±»åˆ«åˆ†ç»„
    categories = {}
    total_size = 0
    
    for file_info in files_info:
        category = file_info['category']
        if category not in categories:
            categories[category] = []
        categories[category].append(file_info)
        total_size += file_info['size']
    
    print(f"ğŸ’¾ æ€»å¤§å°: {round(total_size / 1024 / 1024, 2)} MB")
    print()
    
    # æ˜¾ç¤ºå„ç±»åˆ«æ–‡ä»¶
    for category, files in categories.items():
        print(f"{category} ({len(files)}ä¸ªæ–‡ä»¶)")
        print("-" * 60)
        
        for file_info in files:
            size_str = f"{file_info['size_mb']}{file_info['size_unit']}"
            print(f"  ğŸ“„ {file_info['name']:<40} {size_str:>8}")
            print(f"      {file_info['description']} - {file_info['usage']}")
            print(f"      ä¿®æ”¹æ—¶é—´: {file_info['modified']}")
            print()
    
    # æ˜¾ç¤ºæ¨èä½¿ç”¨æµç¨‹
    print("ğŸš€ æ¨èä½¿ç”¨æµç¨‹:")
    print("-" * 60)
    print("1. python analyze_real_data.py              # åˆ†æOracleæ•°æ®")
    print("2. python generate_standardized_rules.py    # ç”Ÿæˆæ ‡å‡†åŒ–è§„åˆ™")
    print("3. python generate_sql_import_script.py     # ç”ŸæˆSQLå¯¼å…¥è„šæœ¬")
    print("4. psql -f postgresql_import_*.sql          # å¯¼å…¥åˆ°PostgreSQL")
    print("5. python test_generated_rules.py           # æµ‹è¯•è§„åˆ™æ•ˆæœ")
    print()
    
    # æ˜¾ç¤ºå…³é”®æ–‡ä»¶çŠ¶æ€
    key_files = [
        'oracle_data_analysis_20251002_184248.json',
        'standardized_extraction_rules_20251002_184612.json',
        'standardized_synonym_dictionary_20251002_184612.json',
        'postgresql_import_20251002_185603.sql'
    ]
    
    print("ğŸ”‘ å…³é”®æ–‡ä»¶çŠ¶æ€:")
    print("-" * 60)
    for key_file in key_files:
        exists = any(f['name'] == key_file for f in files_info)
        status = "âœ… å­˜åœ¨" if exists else "âŒ ç¼ºå¤±"
        print(f"  {status} {key_file}")
    print()

def save_file_inventory():
    """ä¿å­˜æ–‡ä»¶æ¸…å•åˆ°JSON"""
    files_info = get_file_info()
    
    inventory = {
        'generated_at': datetime.now().isoformat(),
        'total_files': len(files_info),
        'total_size_mb': round(sum(f['size'] for f in files_info) / 1024 / 1024, 2),
        'files': files_info
    }
    
    with open('file_inventory.json', 'w', encoding='utf-8') as f:
        json.dump(inventory, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“‹ æ–‡ä»¶æ¸…å•å·²ä¿å­˜åˆ°: file_inventory.json")

if __name__ == "__main__":
    print_file_summary()
    save_file_inventory()
