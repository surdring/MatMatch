# Task 1.3 ETL数据管道实现 - [S] 规格说明文档

**时间**: 2025-10-04 11:00:00  
**阶段**: S.T.I.R. 开发循环 - [S] Spec阶段  
**任务**: Task 1.3 - ETL数据管道实现  
**状态**: 📋 规格定义中

---

## 📋 核心规格清单

### 1. 任务概述

**任务目标**: 实现Oracle到PostgreSQL的ETL数据管道，支持大规模物料数据的全量和增量同步，并确保对称处理算法的一致性。

**核心价值**: 
- 将Oracle ERP系统中的物料数据同步到PostgreSQL
- 应用对称处理算法（标准化、属性提取、分类检测）
- 为查重系统提供高质量的标准化数据基础

---

## 🎯 输入/输出规格

### 输入规格

#### 1. Oracle数据源

**数据表**:
- `bd_material` - 物料主数据（动态增长，当前约23万条）
- `bd_marbasclass` - 物料分类表（约2,523个分类）
- `bd_measdoc` - 计量单位表（约83个单位）

**筛选条件**:
```sql
WHERE m.enablestate = 2  -- 仅同步已启用物料
```

**字段清单** (通过多表JOIN获取):
```sql
m.code                    -- 物料编码
m.name                    -- 物料名称
m.materialspec            -- 规格
m.materialtype            -- 型号
m.pk_marbasclass          -- 分类外键ID ⭐
c.name as category_name   -- 分类名称 ⭐ JOIN获取
c.code as category_code   -- 分类编码
m.pk_measdoc              -- 单位外键ID ⭐
u.name as unit_name       -- 单位名称 ⭐ JOIN获取
u.ename as unit_english_name -- 单位英文名
m.enablestate             -- 启用状态
m.ename                   -- 英文名称
m.ematerialspec           -- 英文规格
m.materialshortname       -- 简称
m.materialmnecode         -- 助记码
m.memo                    -- 备注
m.creationtime            -- 创建时间
m.modifiedtime            -- 修改时间 ⭐ 增量同步依据
m.pk_org                  -- 组织ID
```

#### 2. PostgreSQL知识库数据

**已存在的表**:
- `extraction_rules` - 6条属性提取规则
- `synonyms` - 约38,068条同义词
- `knowledge_categories` - 约1,594个分类关键词

**用途**: Transform阶段对称处理算法的规则引擎数据

---

### 输出规格

#### 1. PostgreSQL目标表: `materials_master`

**写入字段** (完整清单):

| 字段类别 | 字段名 | 类型 | 来源 | 说明 |
|---------|--------|------|------|------|
| **Oracle原始字段** | erp_code | VARCHAR(40) | m.code | 物料编码（唯一） |
| | material_name | VARCHAR(200) | m.name | 物料名称 |
| | specification | VARCHAR(400) | m.materialspec | 规格 |
| | model | VARCHAR(400) | m.materialtype | 型号 |
| | english_name | VARCHAR(200) | m.ename | 英文名称 |
| | english_spec | VARCHAR(400) | m.ematerialspec | 英文规格 |
| | short_name | VARCHAR(200) | m.materialshortname | 简称 |
| | mnemonic_code | VARCHAR(50) | m.materialmnecode | 助记码 |
| | memo | VARCHAR(100) | m.memo | 备注 |
| | enable_state | INTEGER | m.enablestate | 启用状态 |
| | oracle_created_time | TIMESTAMP | m.creationtime | Oracle创建时间 |
| | oracle_modified_time | TIMESTAMP | m.modifiedtime | Oracle修改时间 |
| **Oracle外键ID** | oracle_category_id | VARCHAR(20) | m.pk_marbasclass | 分类外键 |
| | oracle_unit_id | VARCHAR(20) | m.pk_measdoc | 单位外键 |
| | oracle_org_id | VARCHAR(20) | m.pk_org | 组织外键 |
| **关联名称** | category_name | VARCHAR(200) | c.name (JOIN) | 分类名称 ⭐ |
| | unit_name | VARCHAR(100) | u.name (JOIN) | 单位名称 ⭐ |
| **对称处理输出** | normalized_name | VARCHAR(500) | 算法生成 | 标准化名称 ⭐⭐⭐ |
| | full_description | TEXT | 算法生成 | 完整描述 |
| | attributes | JSONB | 算法生成 | 结构化属性 ⭐⭐⭐ |
| | detected_category | VARCHAR(100) | 算法生成 | 检测类别 ⭐⭐⭐ |
| | category_confidence | DECIMAL(3,2) | 算法生成 | 检测置信度 |
| **处理状态** | last_processed_at | TIMESTAMP | 系统时间 | 最后处理时间 |
| **时间戳** | created_at | TIMESTAMP | 系统时间 | 记录创建时间 |
| | updated_at | TIMESTAMP | 系统时间 | 记录更新时间 |
| **同步状态** | sync_status | VARCHAR(20) | 默认'synced' | 同步状态 |
| | last_sync_at | TIMESTAMP | 系统时间 | 最后同步时间 |

**关键输出字段说明**:
- ⭐⭐⭐ **核心对称处理字段** (用于查重系统):
  - `normalized_name`: 经过标准化和同义词替换的名称
  - `attributes`: 提取的结构化属性（JSONB格式）
  - `detected_category`: 智能检测的物料类别
  
- ⭐ **多表JOIN获取字段**:
  - `category_name`: 通过JOIN bd_marbasclass获取
  - `unit_name`: 通过JOIN bd_measdoc获取

#### 2. ETL任务监控表: `etl_job_logs`

**写入字段**:
```python
{
    "job_id": "uuid",              # 任务唯一ID
    "job_type": "full_sync|incremental_sync",  # 任务类型
    "start_time": "datetime",      # 开始时间
    "end_time": "datetime",        # 结束时间
    "status": "running|success|failed",  # 任务状态
    "total_records": 数量,          # 总记录数（动态增长）
    "processed_records": 150000,   # 已处理数
    "failed_records": 10,          # 失败数
    "error_message": "text",       # 错误信息
    "performance_metrics": {       # 性能指标（JSONB）
        "records_per_minute": 1200,
        "average_batch_time": 45.3
    }
}
```

---

## 🏗️ 系统架构

### 1. 整体数据流

```
┌──────────────────────────────────────────────┐
│  Oracle数据库 (ERP系统)                       │
│  ├── bd_material (物料主数据)                 │
│  ├── bd_marbasclass (分类表)                  │
│  └── bd_measdoc (单位表)                      │
└─────────────┬────────────────────────────────┘
              │
              ▼
┌──────────────────────────────────────────────┐
│  Task 1.2: OracleConnectionAdapter           │
│  职责：提供可复用的Oracle连接管理             │
│  ├── 连接管理 (connect/disconnect)           │
│  ├── 查询执行 (execute_query)                │
│  ├── 流式查询 (execute_query_generator)      │
│  ├── 查询缓存 (QueryCache)                   │
│  └── 自动重试 (async_retry)                  │
└─────────────┬────────────────────────────────┘
              │ execute_query(多表JOIN SQL)
              ▼
┌──────────────────────────────────────────────┐
│  Task 1.3: ETLPipeline (本任务)              │
│                                              │
│  ┌────────────────────────────────────────┐ │
│  │ Extract阶段（数据提取）                 │ │
│  │ ├── _extract_materials_batch()         │ │
│  │ │   └── 构建多表JOIN SQL                │ │
│  │ │       SELECT m.*, c.name, u.name    │ │
│  │ │       FROM bd_material m            │ │
│  │ │       LEFT JOIN bd_marbasclass c    │ │
│  │ │       LEFT JOIN bd_measdoc u        │ │
│  │ │       WHERE m.enablestate = 2       │ │
│  │ │                                      │ │
│  │ └── _extract_materials_incremental()  │ │
│  │     └── 基于modified_time增量提取      │ │
│  └────────────────────────────────────────┘ │
│              ↓                              │
│  ┌────────────────────────────────────────┐ │
│  │ Transform阶段（对称处理）⭐⭐⭐         │ │
│  │ ├── SimpleMaterialProcessor            │ │
│  │ │   ├── 步骤1: 智能分类检测            │ │
│  │ │   │   └── detect_category()         │ │
│  │ │   │       - 加载knowledge_categories │ │
│  │ │   │       - 加权关键词匹配算法        │ │
│  │ │   │                                   │ │
│  │ │   ├── 步骤2: 文本标准化              │ │
│  │ │   │   └── normalize_text()          │ │
│  │ │   │       - 全角半角转换              │ │
│  │ │   │       - 大小写标准化              │ │
│  │ │   │       - 特殊字符清理              │ │
│  │ │   │                                   │ │
│  │ │   ├── 步骤3: 同义词替换              │ │
│  │ │   │   └── apply_synonyms()          │ │
│  │ │   │       - 加载synonyms词典         │ │
│  │ │   │       - Hash表O(1)查找          │ │
│  │ │   │                                   │ │
│  │ │   └── 步骤4: 属性提取                │ │
│  │ │       └── extract_attributes()      │ │
│  │ │           - 加载extraction_rules    │ │
│  │ │           - 正则表达式匹配            │ │
│  │ │                                       │ │
│  │ └── _process_batch()                   │ │
│  │     └── 批量应用对称处理               │ │
│  └────────────────────────────────────────┘ │
│              ↓                              │
│  ┌────────────────────────────────────────┐ │
│  │ Load阶段（批量写入PostgreSQL）         │ │
│  │ ├── _load_batch()                      │ │
│  │ │   ├── 批量INSERT/UPDATE              │ │
│  │ │   ├── 事务管理 (begin/commit)        │ │
│  │ │   ├── 错误处理和回滚                  │ │
│  │ │   └── 进度更新                        │ │
│  │ │                                       │ │
│  │ └── _update_etl_job_log()             │ │
│  │     └── 记录任务状态和性能指标          │ │
│  └────────────────────────────────────────┘ │
│                                              │
│  公共方法:                                   │
│  ├── run_full_sync(callback)               │
│  └── run_incremental_sync(since_time)      │
└─────────────┬────────────────────────────────┘
              │
              ▼
┌──────────────────────────────────────────────┐
│  PostgreSQL数据库                            │
│  ├── materials_master (物料主数据) ⭐        │
│  ├── etl_job_logs (ETL任务日志)             │
│  ├── extraction_rules (提取规则)            │
│  ├── synonyms (同义词词典)                   │
│  └── knowledge_categories (分类关键词)       │
└──────────────────────────────────────────────┘
```

---

### 2. 组件依赖关系

#### 2.1 ETLPipeline核心依赖

```python
class ETLPipeline:
    """
    ETL数据管道主类
    """
    
    def __init__(
        self,
        oracle_adapter: OracleConnectionAdapter,  # Task 1.2适配器
        pg_session: AsyncSession,                  # PostgreSQL会话
        material_processor: SimpleMaterialProcessor # 对称处理器
    ):
        self.oracle_adapter = oracle_adapter
        self.pg_session = pg_session
        self.processor = material_processor
        
        # 统计信息
        self.processed_count = 0
        self.failed_count = 0
        self.start_time = None
        self.current_job_id = None
```

**依赖接口**:

1. **OracleConnectionAdapter** (Task 1.2)
   - `execute_query(query: str, params: Dict) -> List[Dict]`
   - `execute_query_generator(query: str, params: Dict, batch_size: int) -> AsyncGenerator`
   - `connect() -> bool`
   - `disconnect() -> None`

2. **AsyncSession** (SQLAlchemy)
   - `add(instance)` - 添加实例
   - `bulk_save_objects(objects)` - 批量保存
   - `commit()` - 提交事务
   - `rollback()` - 回滚事务

3. **SimpleMaterialProcessor** (本任务实现)
   - `process_material(data: Dict) -> MaterialsMaster`
   - `load_knowledge_base() -> None`

---

#### 2.2 SimpleMaterialProcessor核心依赖

```python
class SimpleMaterialProcessor:
    """
    简化版物料处理器 - 对称处理算法实现
    
    注意：为Task 2.1的UniversalMaterialProcessor预留接口
    """
    
    def __init__(self, pg_session: AsyncSession):
        self.pg_session = pg_session
        
        # 知识库缓存
        self.extraction_rules: List[Dict] = []
        self.synonyms: Dict[str, str] = {}
        self.category_keywords: Dict[str, List[str]] = {}
        
        # 初始化状态
        self._knowledge_base_loaded = False
```

**依赖接口**:

1. **AsyncSession** (SQLAlchemy)
   - `execute(query)` - 执行查询
   - 用于加载知识库数据

2. **PostgreSQL知识库表**
   - `extraction_rules` - 提取规则
   - `synonyms` - 同义词
   - `knowledge_categories` - 分类关键词

---

## 🔧 核心方法规格

### 1. ETLPipeline核心方法

#### 1.1 run_full_sync() - 全量同步

```python
async def run_full_sync(
    self,
    batch_size: int = 1000,
    progress_callback: Optional[Callable[[int, int], None]] = None
) -> Dict[str, Any]:
    """
    执行全量同步
    
    参数:
        batch_size: 每批处理数量（默认1000）
        progress_callback: 进度回调函数 callback(processed, total)
        
    返回:
        {
            "job_id": "uuid",
            "status": "success|failed",
            "total_records": 动态数量,
            "processed_records": 处理数量,
            "failed_records": 失败数量,
            "duration_seconds": 13824.5,
            "records_per_minute": 1000.5
        }
        
    异常:
        ETLError: ETL处理失败
        OracleConnectionError: Oracle连接失败
        
    流程:
        1. 创建ETL任务日志（etl_job_logs）
        2. 连接Oracle（使用Task 1.2适配器）
        3. 批量提取数据（_extract_materials_batch）
        4. 对称处理（_process_batch）
        5. 批量写入PostgreSQL（_load_batch）
        6. 更新任务日志
        7. 返回执行结果
    """
```

**性能要求**:
- 处理速度 ≥ 1000条/分钟
- 批量大小可配置（推荐500-1000）
- 支持进度回调

---

#### 1.2 run_incremental_sync() - 增量同步

```python
async def run_incremental_sync(
    self,
    since_time: str,
    batch_size: int = 1000,
    progress_callback: Optional[Callable[[int, int], None]] = None
) -> Dict[str, Any]:
    """
    执行增量同步
    
    参数:
        since_time: 起始时间（格式：'YYYY-MM-DD HH:MI:SS'）
        batch_size: 每批处理数量
        progress_callback: 进度回调
        
    返回:
        同run_full_sync()
        
    流程:
        1. 创建ETL任务日志（类型=incremental_sync）
        2. 基于modified_time提取增量数据
        3. 对称处理
        4. UPSERT到PostgreSQL（存在则更新，不存在则插入）
        5. 更新任务日志
        
    增量查询条件:
        WHERE m.modifiedtime > TO_TIMESTAMP(:since_time, 'YYYY-MM-DD HH24:MI:SS')
    """
```

**性能要求**:
- 增量延迟 ≤ 1小时
- 支持UPSERT操作
- 避免全表扫描

---

#### 1.3 _extract_materials_batch() - 批量提取数据

```python
async def _extract_materials_batch(
    self,
    batch_size: int = 1000,
    offset: int = 0
) -> AsyncGenerator[List[Dict], None]:
    """
    从Oracle批量提取物料数据（含多表JOIN）⭐核心方法
    
    参数:
        batch_size: 每批数量
        offset: 偏移量
        
    生成器输出:
        批量数据 List[Dict]
        
    SQL查询:
        SELECT 
            m.code as erp_code,
            m.name as material_name,
            m.materialspec as specification,
            m.materialtype as model,
            m.pk_marbasclass as oracle_category_id,
            c.name as category_name,          -- ⭐ JOIN获取
            c.code as category_code,
            m.pk_measdoc as oracle_unit_id,
            u.name as unit_name,              -- ⭐ JOIN获取
            u.ename as unit_english_name,
            m.enablestate as enable_state,
            m.ename as english_name,
            m.ematerialspec as english_spec,
            m.materialshortname as short_name,
            m.materialmnecode as mnemonic_code,
            m.memo as memo,
            m.creationtime as oracle_created_time,
            m.modifiedtime as oracle_modified_time,
            m.pk_org as oracle_org_id
        FROM bd_material m
        LEFT JOIN bd_marbasclass c ON m.pk_marbasclass = c.pk_marbasclass
        LEFT JOIN bd_measdoc u ON m.pk_measdoc = u.pk_measdoc
        WHERE m.enablestate = 2
        ORDER BY m.code
        OFFSET :offset ROWS FETCH NEXT :batch_size ROWS ONLY
        
    使用Task 1.2的方法:
        batch = await self.oracle_adapter.execute_query(query, params)
        
    性能优化:
        - 使用LEFT JOIN避免NULL
        - ORDER BY保证顺序
        - 分批提取减少内存占用
    """
```

---

#### 1.4 _process_batch() - 批量处理数据

```python
async def _process_batch(
    self,
    batch: List[Dict]
) -> List[MaterialsMaster]:
    """
    批量处理数据（对称处理）⭐核心方法
    
    参数:
        batch: 原始数据批次
        
    返回:
        处理后的ORM对象列表
        
    处理流程:
        for item in batch:
            1. 调用 SimpleMaterialProcessor.process_material(item)
            2. 返回 MaterialsMaster ORM对象（包含对称处理结果）
            
    对称处理输出字段:
        - normalized_name: 标准化名称
        - full_description: 完整描述
        - attributes: 结构化属性（JSONB）
        - detected_category: 检测类别
        - category_confidence: 检测置信度
        
    异常处理:
        - 单条记录失败不影响整批
        - 记录失败原因到日志
        - failed_count += 1
    """
```

---

#### 1.5 _load_batch() - 批量写入PostgreSQL

```python
async def _load_batch(
    self,
    materials: List[MaterialsMaster],
    batch_size: int = 500
) -> int:
    """
    批量写入PostgreSQL（带事务管理）⭐核心方法
    
    参数:
        materials: ORM对象列表
        batch_size: 每批写入数量（默认500）
        
    返回:
        成功写入的记录数
        
    流程:
        1. 开启事务（session.begin()）
        2. 批量插入（session.bulk_save_objects()）
        3. 提交事务（session.commit()）
        4. 异常时回滚（session.rollback()）
        
    写入策略:
        - 全量同步：INSERT（erp_code唯一约束）
        - 增量同步：UPSERT（ON CONFLICT DO UPDATE）
        
    性能优化:
        - 批量提交减少I/O
        - 延迟索引创建（全量同步后统一创建）
        - 使用bulk_save_objects而非逐条add
        
    异常处理:
        - IntegrityError: 记录重复，跳过或更新
        - DatabaseError: 回滚事务，记录错误
    """
```

---

### 2. SimpleMaterialProcessor核心方法

#### 2.1 process_material() - 处理单条物料数据

```python
def process_material(
    self,
    data: Dict[str, Any]
) -> MaterialsMaster:
    """
    处理单条物料数据（对称处理算法）⭐⭐⭐核心方法
    
    参数:
        data: Oracle提取的原始数据（含JOIN字段）
        
    返回:
        MaterialsMaster ORM对象（含对称处理结果）
        
    对称处理流程（4步算法）:
        
        # 步骤0: 构建完整描述
        full_description = self._build_full_description(data)
        # 输入: {"material_name": "深沟球軸承", "specification": "６２０６", "model": "ＳＫＦ"}
        # 输出: "深沟球軸承 ６２０６ ＳＫＦ"
        
        # 步骤1: 智能分类检测
        detected_category, confidence = self._detect_category(full_description)
        # 输入: "深沟球軸承 ６２０６ ＳＫＦ"
        # 输出: ("轴承", 0.85)
        
        # 步骤2: 文本标准化
        normalized_text = self._normalize_text(full_description)
        # 输入: "深沟球軸承 ６２０６ ＳＫＦ"
        # 输出: "深沟球轴承 6206 SKF"  (全角→半角)
        
        # 步骤3: 同义词替换
        standardized_text = self._apply_synonyms(normalized_text)
        normalized_name = self._extract_core_name(standardized_text)
        # 输入: "深沟球轴承 6206 SKF"
        # 输出: "深沟球轴承 6206"  (去除品牌)
        
        # 步骤4: 属性提取
        attributes = self._extract_attributes(standardized_text, detected_category)
        # 输入: "深沟球轴承 6206 SKF"
        # 输出: {"brand_name": "SKF", "bearing_code": "6206", "bearing_type": "深沟球"}
        
    返回ORM对象:
        MaterialsMaster(
            # Oracle原始字段
            erp_code=data['erp_code'],
            material_name=data['material_name'],
            specification=data.get('specification'),
            model=data.get('model'),
            # ... 其他Oracle字段 ...
            
            # JOIN字段
            oracle_category_id=data.get('oracle_category_id'),
            category_name=data.get('category_name'),  # ⭐ JOIN获取
            oracle_unit_id=data.get('oracle_unit_id'),
            unit_name=data.get('unit_name'),          # ⭐ JOIN获取
            
            # 对称处理输出
            normalized_name=normalized_name,          # ⭐⭐⭐
            full_description=full_description,
            attributes=attributes,                    # ⭐⭐⭐
            detected_category=detected_category,      # ⭐⭐⭐
            category_confidence=confidence,
            
            # 处理时间
            last_processed_at=datetime.now(),
            sync_status='synced',
            last_sync_at=datetime.now()
        )
    """
```

**对称处理核心算法详解**:

##### 步骤1: 智能分类检测

```python
def _detect_category(
    self,
    description: str
) -> Tuple[str, float]:
    """
    智能分类检测算法
    
    数据源: knowledge_categories表（约1,594个分类）
    
    算法:
        1. 将description转为小写
        2. 遍历所有分类的关键词
        3. 计算匹配得分 = 匹配数 / 总关键词数
        4. 返回得分最高的分类
        
    示例:
        输入: "深沟球轴承 6206 SKF"
        knowledge_categories:
            - "轴承": ["轴承", "bearing", "滚动", "深沟球", "圆锥", ...]
            - "阀门": ["阀门", "valve", "球阀", "闸阀", ...]
            - "管件": ["管", "pipe", "弯头", "三通", ...]
        
        计算:
            "轴承" 匹配: ["轴承", "深沟球"] -> 2/15 = 0.13
            但因为是高权重关键词，实际得分: 0.85
        
        输出: ("轴承", 0.85)
        
    性能优化:
        - 缓存category_keywords（5分钟TTL）
        - 关键词小写化预处理
        - 使用set加速in操作
    """
```

##### 步骤2: 文本标准化

```python
def _normalize_text(
    self,
    text: str
) -> str:
    """
    文本标准化
    
    算法:
        1. 全角转半角（76个字符对）
           "０１２３...ＡＢＣ...ａｂｃ...×＊" -> "0123...ABC...abc...*x"
        2. 去除多余空格
           "  text   test  " -> "text test"
        3. 统一大小写（品牌名保留）
           "skf" -> "SKF" (品牌识别)
           
    示例:
        输入: "不锈钢管　ＤＮ５０　Φ１００"
        输出: "不锈钢管 DN50 Φ100"
    """
```

##### 步骤3: 同义词替换

```python
def _apply_synonyms(
    self,
    text: str
) -> str:
    """
    同义词替换算法
    
    数据源: synonyms表（约38,068条记录）
    
    算法:
        1. 分词（按空格）
        2. Hash表O(1)查找替换
        3. 重组文本
        
    示例:
        输入: "不锈钢 SUS304 Ф50"
        synonyms:
            "SUS304" -> "304"
            "Ф" -> "Φ"
            "stainless" -> "不锈钢"
        输出: "不锈钢 304 Φ50"
        
    性能优化:
        - 使用Python dict（Hash表）实现O(1)查找
        - 缓存synonym_dict
        - 预编译正则表达式（如果使用正则替换）
    """
```

##### 步骤4: 属性提取

```python
def _extract_attributes(
    self,
    text: str,
    category: str
) -> Dict[str, str]:
    """
    属性提取算法
    
    数据源: extraction_rules表（6条规则）
    
    算法:
        1. 按优先级排序规则
        2. 过滤适用于当前类别的规则
        3. 依次应用正则表达式
        4. 构建属性字典
        
    6条核心规则:
        规则1: 尺寸规格提取 - (\d+(?:\.\d+)?[×xX*]\d+(?:\.\d+)?)
        规则2: 螺纹规格提取 - (M\d+(?:\.\d+)?[×*xX]\d+(?:\.\d+)?)
        规则3: 材质类型提取 - (304|316|Q235|45#|不锈钢|碳钢|合金钢|铸铁)
        规则4: 品牌名称提取 - \b(SKF|FAG|NSK|...)\b
        规则5: 压力等级提取 - (PN\d+|\d+(?:\.\d+)?(?:MPa|bar))
        规则6: 公称直径提取 - (DN\d+|Φ\d+|φ\d+)
        
    示例:
        输入: ("不锈钢管 DN50 Φ100 304", "管件")
        输出: {
            "nominal_diameter": "DN50",
            "outer_diameter": "Φ100",
            "material_type": "304"
        }
    """
```

---

## 📊 性能要求

### 1. 处理速度

| 指标 | 目标值 | 测量方法 |
|------|--------|---------|
| **处理速度** | ≥ 1000条/分钟 | records_per_minute = total / (duration_seconds / 60) |
| **批量大小** | 500-1000条/批 | 可配置 |
| **全量同步时间** | ≤ 4小时 | 基于当前数据规模估算 |
| **增量同步延迟** | ≤ 1小时 | 从Oracle修改到PostgreSQL可查询 |

### 2. 数据质量

| 指标 | 目标值 | 验证方法 |
|------|--------|---------|
| **同步准确率** | ≥ 99.9% | 对比Oracle和PostgreSQL记录数 |
| **对称处理一致性** | ≥ 99.9% | ETL结果 vs 在线处理结果（1000个样本） |
| **字段完整性** | 100% | 必填字段不为NULL |
| **外键关联正确性** | 100% | category_name和unit_name正确关联 |

### 3. 系统健壮性

| 指标 | 目标值 | 实现方式 |
|------|--------|---------|
| **错误恢复** | 自动重试3次 | 使用async_retry装饰器 |
| **事务完整性** | ACID保证 | PostgreSQL事务管理 |
| **断点续传** | 支持 | 基于offset参数 |
| **监控日志** | 完善 | etl_job_logs表记录 |

---

## 🔍 对称处理验证规格 ⭐⭐⭐

### 核心验证目标

**验证问题**: ETL处理的结果与在线API处理的结果是否一致？

**验证意义**: 确保查重系统能正常工作（ETL标准化的数据 = 在线查询标准化的数据）

### 验证方法

```python
# backend/scripts/verify_etl_symmetry.py

async def verify_etl_symmetry(
    sample_size: int = 1000
) -> Dict[str, Any]:
    """
    验证ETL对称处理一致性
    
    流程:
        1. 从materials_master随机抽取1000个样本
        2. 提取Oracle原始字段（material_name, specification, model）
        3. 使用SimpleMaterialProcessor重新处理
        4. 对比ETL结果和在线处理结果
        
    对比字段:
        - normalized_name: 标准化名称一致性
        - attributes: 属性提取一致性
        - detected_category: 分类检测一致性
        
    一致性计算:
        consistency_rate = matched_count / total_count * 100%
        
    目标: consistency_rate ≥ 99.9%
    """
```

### 验证示例

**样本数据**:
```json
{
    "erp_code": "MAT001",
    "material_name": "深沟球軸承",
    "specification": "６２０６",
    "model": "ＳＫＦ"
}
```

**ETL处理结果** (写入PostgreSQL):
```json
{
    "normalized_name": "深沟球轴承 6206",
    "attributes": {
        "brand_name": "SKF",
        "bearing_code": "6206",
        "bearing_type": "深沟球"
    },
    "detected_category": "轴承",
    "category_confidence": 0.85
}
```

**在线重新处理** (SimpleMaterialProcessor):
```json
{
    "normalized_name": "深沟球轴承 6206",  // ✅ 一致
    "attributes": {
        "brand_name": "SKF",               // ✅ 一致
        "bearing_code": "6206",            // ✅ 一致
        "bearing_type": "深沟球"           // ✅ 一致
    },
    "detected_category": "轴承",           // ✅ 一致
    "category_confidence": 0.85            // ✅ 一致
}
```

**结果**: ✅ **100% 一致**

---

## 📦 交付物清单

### 1. 代码文件

| 文件路径 | 说明 | 状态 |
|---------|------|------|
| `backend/etl/__init__.py` | ETL模块初始化 | 待创建 |
| `backend/etl/etl_pipeline.py` | ETL管道主类 | 待创建 |
| `backend/etl/material_processor.py` | SimpleMaterialProcessor实现 | 待创建 |
| `backend/etl/etl_config.py` | ETL配置类 | 待创建 |
| `backend/etl/exceptions.py` | ETL自定义异常 | 待创建 |

### 2. 测试文件

| 文件路径 | 说明 | 状态 |
|---------|------|------|
| `backend/tests/test_etl_pipeline.py` | ETL管道单元测试 | 待创建 |
| `backend/tests/test_material_processor.py` | 物料处理器测试 | 待创建 |
| `backend/tests/test_symmetric_processing.py` | 对称处理集成测试 | 待创建 |

### 3. 脚本文件

| 文件路径 | 说明 | 状态 |
|---------|------|------|
| `backend/scripts/verify_etl_symmetry.py` | 对称性验证工具 | 待创建 |
| `backend/scripts/run_etl_sync.py` | ETL同步执行脚本 | 待创建 |

### 4. 文档文件

| 文件路径 | 说明 | 状态 |
|---------|------|------|
| `backend/etl/README.md` | ETL模块使用文档 | 待创建 |
| `.gemini_logs/2025-10-04/11-00-00-Task1.3[S]规格说明文档.md` | 本文档 | ✅ 已创建 |

---

## ⚠️ 风险和约束

### 1. 技术风险

| 风险项 | 影响 | 概率 | 缓解措施 |
|--------|------|------|---------|
| **Oracle JOIN性能** | 高 | 中 | - 优化SQL查询<br>- 添加Oracle索引（需DBA支持）<br>- 分批处理 |
| **PostgreSQL写入性能** | 高 | 低 | - 批量提交<br>- 优化事务大小<br>- 延迟索引创建 |
| **内存占用** | 中 | 中 | - 流式处理<br>- 控制批量大小<br>- 及时释放资源 |
| **网络稳定性** | 中 | 中 | - 实现重试机制<br>- 断点续传<br>- 错误恢复 |

### 2. 依赖约束

| 依赖项 | 状态 | 约束 | 影响 |
|--------|------|------|------|
| **Task 1.2** | ✅ 完成 | 必须先完成重构版Task 1.2 | 已满足 |
| **Task 1.1** | ✅ 完成 | 知识库数据必须已导入PostgreSQL | 已满足 |
| **Oracle连接** | ✅ 可用 | 需要Oracle数据库访问权限 | 已满足 |
| **PostgreSQL** | ✅ 可用 | 需要materials_master表已创建 | 已满足 |

### 3. 业务约束

| 约束项 | 说明 | 影响 |
|--------|------|------|
| **数据规模动态增长** | 当前数据规模会持续增长 | 需要确保性能可扩展 |
| **ETL窗口时间** | 全量同步建议在非工作时间执行（夜间） | 需要调度支持 |
| **数据一致性** | Oracle为ERP主数据源，不可修改 | 单向同步，只读取Oracle |

---

## 📝 下一步计划

### [S] Spec阶段 - 当前进度

- [x] 编写完整Spec清单 ✅
- [ ] 设计SimpleMaterialProcessor接口和实现策略
- [ ] 设计ETLPipeline架构细节

### [T] Test阶段 - 待开始

- [ ] 设计核心功能测试用例（5-8个）
- [ ] 设计边界情况测试用例（5-7个）
- [ ] 设计对称处理验证测试（核心验证）

### [I] Implement阶段 - 待开始

- [ ] 创建ETL目录结构和基础文件
- [ ] 实现SimpleMaterialProcessor（对称处理算法）
- [ ] 实现ETLPipeline主类
- [ ] 实现增量同步功能
- [ ] 创建对称性验证脚本

### [R] Review阶段 - 待开始

- [ ] 运行完整测试套件
- [ ] 性能基准测试（≥1000条/分钟）
- [ ] 对称处理验证（≥99.9%一致性）
- [ ] 代码质量审查和文档完善

---

**编写人**: AI Assistant  
**编写时间**: 2025-10-04 11:00  
**版本**: v1.0  
**文档状态**: 📋 规格定义完成
