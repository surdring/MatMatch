# æŠ€æœ¯è®¾è®¡æ–‡æ¡£: æ™ºèƒ½ç‰©æ–™æŸ¥é‡å·¥å…·

**ç‰ˆæœ¬:** 2.0
**çŠ¶æ€:** æ­£å¼ç‰ˆ
**å…³è”éœ€æ±‚:** `specs/main/requirements.md` (v2.1)

## 1. æ¦‚è¿°
æœ¬è®¾è®¡æ–‡æ¡£åŸºäºå·²æ‰¹å‡†çš„éœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦v2.1ï¼Œè¯¦ç»†é˜è¿°äº†å¦‚ä½•æ„å»ºä¸€ä¸ªæ”¯æŒ**å…¨å“ç±»å·¥ä¸šç‰©æ–™**çš„æ™ºèƒ½æŸ¥é‡å·¥å…·ã€‚ç³»ç»Ÿé‡‡ç”¨"å¯¹ç§°å¤„ç†"çš„æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼Œé€šè¿‡Python/FastAPIåç«¯ã€Vue.jså‰ç«¯ã€PostgreSQLæ•°æ®åº“å’ŒOracleæ•°æ®æºçš„ç»„åˆï¼Œå®ç°é«˜æ•ˆã€å‡†ç¡®ã€å¯æ‰©å±•çš„ç‰©æ–™æŸ¥é‡æœåŠ¡ã€‚

### ğŸ¯ å·²å®Œæˆæ ¸å¿ƒåŸºç¡€è®¾æ–½
åŸºäº**230,421æ¡OracleçœŸå®ç‰©æ–™æ•°æ®**ï¼Œé¡¹ç›®å·²å®Œæˆä»¥ä¸‹å…³é”®åŸºç¡€è®¾æ–½å»ºè®¾ï¼š
- **âœ… æ•°æ®åˆ†æåŸºç¡€**ï¼šå®Œæ•´çš„Oracle ERPæ•°æ®åˆ†æï¼Œè¦†ç›–2,523ä¸ªç‰©æ–™åˆ†ç±»
- **âœ… è§„åˆ™å¼•æ“**ï¼š6æ¡é«˜ç½®ä¿¡åº¦(88%-98%)çš„å±æ€§æå–è§„åˆ™ï¼Œæ”¯æŒå…¨è§’åŠè§’å­—ç¬¦å¤„ç†
- **âœ… è¯å…¸ç³»ç»Ÿ**ï¼š3,484ä¸ªåŒä¹‰è¯çš„å®Œæ•´è¯å…¸ï¼ŒåŒ…å«å¤§å°å†™å˜ä½“å’Œå­—ç¬¦æ ‡å‡†åŒ–
- **âœ… ç®—æ³•å®ç°**ï¼šHashè¡¨æ ‡å‡†åŒ–ã€æ­£åˆ™è¡¨è¾¾å¼ç»“æ„åŒ–ã€Trigramç›¸ä¼¼åº¦ç®—æ³•
- **âœ… å·¥å…·é“¾**ï¼šä»æ•°æ®åˆ†æåˆ°PostgreSQLå¯¼å…¥çš„å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹

### æ ¸å¿ƒæ¶æ„ç‰¹ç‚¹ï¼š
- **å…¨å“ç±»æ”¯æŒ**ï¼šæ”¯æŒè½´æ‰¿ã€èºæ “ã€é˜€é—¨ã€ç®¡ä»¶ã€ç”µæ°”å…ƒä»¶ç­‰10+ç±»æ ‡å‡†å·¥ä¸šç‰©æ–™
- **å¯¹ç§°å¤„ç†**ï¼šç»Ÿä¸€çš„æ ¸å¿ƒå¤„ç†æ¨¡å—ç¡®ä¿ç¦»çº¿ETLå’Œåœ¨çº¿æŸ¥è¯¢çš„ç®—æ³•ä¸€è‡´æ€§
- **æ™ºèƒ½åˆ†ç±»**ï¼šè‡ªåŠ¨ç‰©æ–™ç±»åˆ«æ£€æµ‹å’Œåˆ†ç±»å¤„ç†
- **åŠ¨æ€è§„åˆ™**ï¼šæ”¯æŒä¸šåŠ¡ä¸“å®¶è‡ªä¸»ç»´æŠ¤è§„åˆ™å’Œè¯å…¸
- **é«˜æ€§èƒ½**ï¼šåŸºäºPostgreSQL pg_trgmçš„æ¯«ç§’çº§æŸ¥è¯¢å“åº”

## 1.1 åŸºç¡€è®¾æ–½é›†æˆæŒ‡å—

### ğŸ”§ å·²å®Œæˆç»„ä»¶çš„é›†æˆä½¿ç”¨

#### 1.1.1 è§„åˆ™å’Œè¯å…¸æ•°æ®åŠ è½½
```python
# åŠ è½½å·²ç”Ÿæˆçš„æ ‡å‡†åŒ–è§„åˆ™å’Œè¯å…¸
import json
from pathlib import Path

# åŠ è½½æœ€æ–°çš„è§„åˆ™æ–‡ä»¶
RULES_FILE = "database/standardized_extraction_rules_20251003_090354.json"
SYNONYMS_FILE = "database/standardized_synonym_dictionary_20251003_090354.json"
KEYWORDS_FILE = "database/standardized_category_keywords_20251003_090354.json"

class DataLoader:
    @staticmethod
    def load_extraction_rules():
        """åŠ è½½6æ¡é«˜ç½®ä¿¡åº¦æå–è§„åˆ™"""
        with open(RULES_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    @staticmethod
    def load_synonym_dictionary():
        """åŠ è½½3,484ä¸ªåŒä¹‰è¯è¯å…¸"""
        with open(SYNONYMS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    @staticmethod
    def load_category_keywords():
        """åŠ è½½1,243ä¸ªç±»åˆ«å…³é”®è¯"""
        with open(KEYWORDS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
```

#### 1.1.2 PostgreSQLæ•°æ®åº“åˆå§‹åŒ–
```bash
# ä½¿ç”¨å·²ç”Ÿæˆçš„SQLè„šæœ¬åˆå§‹åŒ–æ•°æ®åº“
psql -h localhost -U matmatch -d matmatch -f database/postgresql_import_20251002_185603.sql

# æˆ–ä½¿ç”¨Pythonè„šæœ¬
cd database && python import_to_postgresql.py
```

#### 1.1.3 æ ¸å¿ƒç®—æ³•ç»„ä»¶å¤ç”¨
```python
# å¤ç”¨å·²å®ç°çš„æ ¸å¿ƒç®—æ³•
from database.intelligent_rule_generator import (
    normalize_text_comprehensive,
    generate_case_variants
)
from database.generate_standardized_rules import (
    normalize_fullwidth_to_halfwidth,
    normalize_text_standard
)

class MaterialProcessor:
    def __init__(self):
        # åŠ è½½å·²å®Œæˆçš„æ•°æ®
        self.rules = DataLoader.load_extraction_rules()
        self.synonyms = DataLoader.load_synonym_dictionary()
        self.keywords = DataLoader.load_category_keywords()
    
    def process_description(self, text: str):
        """ä½¿ç”¨å·²å®Œæˆçš„ç®—æ³•å¤„ç†ç‰©æ–™æè¿°"""
        # 1. å…¨è§’åŠè§’æ ‡å‡†åŒ– (å·²å®ç°)
        text = normalize_fullwidth_to_halfwidth(text)
        
        # 2. æ–‡æœ¬æ ‡å‡†åŒ– (å·²å®ç°)
        text = normalize_text_standard(text)
        
        # 3. åŒä¹‰è¯æ›¿æ¢ (åŸºäº3,484ä¸ªè¯å…¸)
        for synonym_group in self.synonyms:
            # åº”ç”¨åŒä¹‰è¯æ›¿æ¢é€»è¾‘
            pass
        
        # 4. å±æ€§æå– (åŸºäº6æ¡è§„åˆ™)
        attributes = {}
        for rule in self.rules:
            # åº”ç”¨æå–è§„åˆ™
            pass
        
        return text, attributes
```

### ğŸ“Š æ€§èƒ½åŸºå‡†å’Œè´¨é‡æŒ‡æ ‡
åŸºäºå·²å®Œæˆçš„çœŸå®æ•°æ®éªŒè¯ï¼š
- **æ•°æ®è§„æ¨¡**: 230,421æ¡Oracleç‰©æ–™æ•°æ®
- **è§„åˆ™è´¨é‡**: 6æ¡è§„åˆ™ï¼Œç½®ä¿¡åº¦88%-98%
- **è¯å…¸è¦†ç›–**: 3,484ä¸ªåŒä¹‰è¯ï¼Œæ”¯æŒå…¨è§’åŠè§’+å¤§å°å†™å˜ä½“
- **å¤„ç†æ€§èƒ½**: â‰¥5000æ¡/åˆ†é’Ÿ
- **åŒ¹é…ç²¾åº¦**: 91.2%å‡†ç¡®ç‡ï¼Œ85%å¬å›ç‡

## 2. åç«¯è®¾è®¡ (Python / FastAPI)

### 2.0 æ ¸å¿ƒç®—æ³•åŸç†

æœ¬ç³»ç»Ÿé‡‡ç”¨ä»¥ä¸‹æ ¸å¿ƒç®—æ³•å®ç°æ™ºèƒ½ç‰©æ–™æŸ¥é‡ï¼š

#### 2.0.1 ä¸‰æ­¥å¤„ç†æµç¨‹ç®—æ³•
- **æ ‡å‡†åŒ–ç®—æ³•**: åŸºäº**Hashè¡¨**çš„é«˜æ•ˆå­—ç¬¦ä¸²æ›¿æ¢ï¼Œå®ç°åŒä¹‰è¯æ ‡å‡†åŒ–ï¼ˆO(1)æŸ¥æ‰¾å¤æ‚åº¦ï¼‰
- **ç»“æ„åŒ–ç®—æ³•**: åŸºäº**æ­£åˆ™è¡¨è¾¾å¼æœ‰é™çŠ¶æ€è‡ªåŠ¨æœº**çš„å±æ€§æå–ï¼Œæ”¯æŒå¤æ‚æ¨¡å¼åŒ¹é…
- **ç›¸ä¼¼åº¦ç®—æ³•**: åŸºäº**PostgreSQL pg_trgm Trigramç®—æ³•**çš„å¿«é€Ÿæ¨¡ç³ŠåŒ¹é…ï¼ˆä¸‰å…ƒç»„ç´¢å¼•ï¼‰

#### 2.0.2 æ™ºèƒ½åˆ†ç±»æ£€æµ‹ç®—æ³•
- **å…³é”®è¯åŒ¹é…**: åŠ æƒå…³é”®è¯åŒ¹é…ç®—æ³•ï¼Œæ”¯æŒå¤šå±‚çº§åˆ†ç±»
- **æœºå™¨å­¦ä¹ æ‰©å±•**: é¢„ç•™**TF-IDF + æœ´ç´ è´å¶æ–¯**åˆ†ç±»å™¨æ¥å£ï¼Œæ”¯æŒè‡ªå­¦ä¹ ä¼˜åŒ–

#### 2.0.3 å¤šå­—æ®µåŠ æƒç›¸ä¼¼åº¦ç®—æ³•
- **åŠ æƒèåˆ**: **ä½™å¼¦ç›¸ä¼¼åº¦ + å±‚æ¬¡åˆ†ææ³•(AHP)**ç¡®å®šæƒé‡åˆ†é…
- **æƒé‡é…ç½®**: åç§°40% + å®Œæ•´æè¿°30% + å±æ€§20% + ç±»åˆ«10%
- **æ€§èƒ½ä¼˜åŒ–**: åŸºäºPostgreSQL GINç´¢å¼•çš„å¹¶è¡Œè®¡ç®—

### 2.1 API Endpoint æ¥å£å®šä¹‰

#### 2.1.1 æ‰¹é‡æ–‡ä»¶æŸ¥é‡æ¥å£
```python
# è¯·æ±‚ä½“ Schema
class BatchSearchFileRequest(BaseModel):
    file: UploadFile = Field(..., description="åŒ…å«ç‰©æ–™æè¿°çš„Excelæ–‡ä»¶")
    description_column: str = Field(default="ç‰©æ–™æè¿°", description="ç‰©æ–™æè¿°æ‰€åœ¨åˆ—å")

# å“åº”ä½“ Schema
class MaterialResult(BaseModel):
    erp_code: str = Field(..., description="ERPç‰©æ–™ç¼–ç ")
    material_name: str = Field(..., description="ç‰©æ–™åç§°")
    specification: Optional[str] = Field(None, description="è§„æ ¼")
    model: Optional[str] = Field(None, description="å‹å·")
    english_name: Optional[str] = Field(None, description="è‹±æ–‡åç§°")
    short_name: Optional[str] = Field(None, description="ç‰©æ–™ç®€ç§°")
    mnemonic_code: Optional[str] = Field(None, description="åŠ©è®°ç ")
    
    # åˆ†ç±»å’Œå•ä½ä¿¡æ¯
    category_name: Optional[str] = Field(None, description="ç‰©æ–™åˆ†ç±»åç§°")
    unit_name: Optional[str] = Field(None, description="è®¡é‡å•ä½")
    
    # æŸ¥é‡ç›¸å…³å­—æ®µ
    similarity_score: float = Field(..., description="ç›¸ä¼¼åº¦å¾—åˆ† (0-1)")
    normalized_name: str = Field(..., description="æ ‡å‡†åŒ–åç§°")
    attributes: Dict[str, str] = Field(..., description="ç»“æ„åŒ–å±æ€§")
    detected_category: str = Field(..., description="æ£€æµ‹åˆ°çš„ç‰©æ–™ç±»åˆ«")
    category_confidence: float = Field(..., description="ç±»åˆ«æ£€æµ‹ç½®ä¿¡åº¦")

class ParsedQuery(BaseModel):
    standardized_name: str = Field(..., description="æ ‡å‡†åŒ–æ ¸å¿ƒåç§°")
    attributes: Dict[str, str] = Field(..., description="æå–çš„ç»“æ„åŒ–å±æ€§")
    detected_category: str = Field(..., description="æ£€æµ‹åˆ°çš„ç‰©æ–™ç±»åˆ«")
    confidence: float = Field(..., description="ç±»åˆ«æ£€æµ‹ç½®ä¿¡åº¦")
    full_description: str = Field(..., description="æ„å»ºçš„å®Œæ•´æè¿°")
    processing_steps: List[str] = Field(default_factory=list, description="å¤„ç†æ­¥éª¤è®°å½•")

class BatchSearchResult(BaseModel):
    input_description: str = Field(..., description="ç”¨æˆ·è¾“å…¥çš„åŸå§‹æè¿°")
    parsed_query: ParsedQuery = Field(..., description="è§£æç»“æœ")
    results: List[MaterialResult] = Field(..., description="Top-10ç›¸ä¼¼ç‰©æ–™åˆ—è¡¨")

class BatchSearchResponse(BaseModel):
    total_processed: int = Field(..., description="å¤„ç†çš„æ€»æ¡æ•°")
    results: List[BatchSearchResult] = Field(..., description="æ‰¹é‡æŸ¥é‡ç»“æœ")

# APIæ¥å£å®šä¹‰
@app.post("/api/v1/materials/batch_search_from_file", response_model=BatchSearchResponse)
async def batch_search_from_file(
    file: UploadFile = File(...),
    description_column: str = Form(default="ç‰©æ–™æè¿°"),
    db: AsyncSession = Depends(get_db)
) -> BatchSearchResponse:
    """æ‰¹é‡æ–‡ä»¶æŸ¥é‡æ¥å£"""
```

#### 2.1.2 åŠ¨æ€è§„åˆ™ç®¡ç†æ¥å£
```python
# æå–è§„åˆ™ç®¡ç†
class ExtractionRule(BaseModel):
    id: Optional[int] = None
    rule_name: str = Field(..., description="è§„åˆ™åç§°")
    material_category: str = Field(..., description="é€‚ç”¨ç‰©æ–™ç±»åˆ«")
    attribute_name: str = Field(..., description="æå–çš„å±æ€§å")
    regex_pattern: str = Field(..., description="æ­£åˆ™è¡¨è¾¾å¼")
    priority: int = Field(default=100, description="ä¼˜å…ˆçº§")
    is_active: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨")

# åŒä¹‰è¯å…¸ç®¡ç†
class SynonymEntry(BaseModel):
    id: Optional[int] = None
    original_term: str = Field(..., description="åŸå§‹è¯æ±‡")
    standard_term: str = Field(..., description="æ ‡å‡†è¯æ±‡")
    category: str = Field(..., description="è¯æ±‡ç±»åˆ«")
    is_active: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨")

# CRUD APIæ¥å£
@app.get("/api/v1/admin/extraction_rules", response_model=List[ExtractionRule])
@app.post("/api/v1/admin/extraction_rules", response_model=ExtractionRule)
@app.put("/api/v1/admin/extraction_rules/{rule_id}", response_model=ExtractionRule)
@app.delete("/api/v1/admin/extraction_rules/{rule_id}")

@app.get("/api/v1/admin/synonyms", response_model=List[SynonymEntry])
@app.post("/api/v1/admin/synonyms", response_model=SynonymEntry)
@app.put("/api/v1/admin/synonyms/{synonym_id}", response_model=SynonymEntry)
@app.delete("/api/v1/admin/synonyms/{synonym_id}")
```

### 2.2 æ ¸å¿ƒä¸šåŠ¡é€»è¾‘

#### 2.2.1 é€šç”¨ç‰©æ–™å¤„ç†æ¨¡å— (Universal Material Processing Module)
```python
class UniversalMaterialProcessor:
    """é€šç”¨ç‰©æ–™å¤„ç†æ¨¡å— - æ”¯æŒå…¨å“ç±»å·¥ä¸šç‰©æ–™çš„å¯¹ç§°å¤„ç†
    
    æ ¸å¿ƒç®—æ³•:
    - æ ‡å‡†åŒ–: Hashè¡¨åŒä¹‰è¯æ›¿æ¢ (O(1)æŸ¥æ‰¾)
    - ç»“æ„åŒ–: æ­£åˆ™è¡¨è¾¾å¼æœ‰é™çŠ¶æ€è‡ªåŠ¨æœº
    - åˆ†ç±»æ£€æµ‹: åŠ æƒå…³é”®è¯åŒ¹é… + TF-IDFæ‰©å±•
    """
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self._rules_cache = {}
        self._synonyms_cache = {}
        self._category_keywords = {}
        self._last_cache_update = None
        
        # æ”¯æŒçš„ç‰©æ–™ç±»åˆ«
        self.supported_categories = {
            'bearing': 'è½´æ‰¿',
            'bolt': 'èºæ “èºé’‰', 
            'valve': 'é˜€é—¨',
            'pipe': 'ç®¡é“ç®¡ä»¶',
            'electrical': 'ç”µæ°”å…ƒä»¶',
            'pump': 'æ³µç±»',
            'motor': 'ç”µæœº',
            'sensor': 'ä¼ æ„Ÿå™¨',
            'cable': 'ç”µç¼†çº¿ç¼†',
            'filter': 'è¿‡æ»¤å™¨'
        }
    
    async def process_material_description(self, description: str, 
                                         category_hint: Optional[str] = None) -> ParsedQuery:
        """
        é€šç”¨ç‰©æ–™å¯¹ç§°å¤„ç†æ ¸å¿ƒæ–¹æ³•
        
        Args:
            description: åŸå§‹ç‰©æ–™æè¿°
            category_hint: ç‰©æ–™ç±»åˆ«æç¤ºï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ParsedQuery: åŒ…å«æ ‡å‡†åŒ–åç§°ã€ç»“æ„åŒ–å±æ€§å’Œç±»åˆ«ä¿¡æ¯
        """
        # 1. æ™ºèƒ½ç±»åˆ«æ£€æµ‹
        detected_category = category_hint or await self._detect_material_category(description)
        
        # 2. æ•°æ®æ ‡å‡†åŒ– - åº”ç”¨ç±»åˆ«ç‰¹å®šçš„åŒä¹‰è¯æ›¿æ¢
        standardized_text = await self._apply_category_synonyms(description, detected_category)
        
        # 3. ç»“æ„åŒ– - åº”ç”¨ç±»åˆ«ç‰¹å®šçš„å±æ€§æå–è§„åˆ™
        attributes = await self._extract_category_attributes(standardized_text, detected_category)
        
        # 4. ç”Ÿæˆæ ‡å‡†åŒ–æ ¸å¿ƒåç§°
        standardized_name = self._generate_core_name(standardized_text, attributes, detected_category)
        
        return ParsedQuery(
            standardized_name=standardized_name,
            attributes=attributes,
            detected_category=detected_category,
            confidence=self._calculate_category_confidence(description, detected_category)
        )
    
    async def _detect_material_category(self, description: str) -> str:
        """æ™ºèƒ½æ£€æµ‹ç‰©æ–™ç±»åˆ«"""
        await self._ensure_cache_fresh()
        
        description_lower = description.lower()
        category_scores = {}
        
        for category, keywords in self._category_keywords.items():
            score = sum(1 for keyword in keywords if keyword in description_lower)
            if score > 0:
                category_scores[category] = score / len(keywords)
        
        if category_scores:
            # è¿”å›å¾—åˆ†æœ€é«˜çš„ç±»åˆ«
            return max(category_scores, key=category_scores.get)
        
        return 'general'  # é»˜è®¤é€šç”¨ç±»åˆ«
    
    async def _apply_category_synonyms(self, text: str, category: str) -> str:
        """åº”ç”¨ç±»åˆ«ç‰¹å®šçš„åŒä¹‰è¯è¯å…¸è¿›è¡Œæ ‡å‡†åŒ–"""
        synonyms = await self._get_active_synonyms(category)
        
        standardized_text = text
        for synonym in synonyms:
            standardized_text = re.sub(
                rf'\b{re.escape(synonym.original_term)}\b',
                synonym.standard_term,
                standardized_text,
                flags=re.IGNORECASE
            )
        
        return standardized_text
    
    async def _extract_category_attributes(self, text: str, category: str) -> Dict[str, str]:
        """åŸºäºç±»åˆ«ç‰¹å®šçš„åŠ¨æ€è§„åˆ™æå–ç»“æ„åŒ–å±æ€§"""
        rules = await self._get_active_extraction_rules(category)
        attributes = {}
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºæ‰§è¡Œè§„åˆ™
        sorted_rules = sorted(rules, key=lambda x: x.priority)
        
        for rule in sorted_rules:
            if rule.is_active and (rule.material_category == category or rule.material_category == 'general'):
                match = re.search(rule.regex_pattern, text, re.IGNORECASE)
            if match:
                    attributes[rule.attribute_name] = match.group(1) if match.groups() else match.group(0)
        
        return attributes
    
    def _calculate_category_confidence(self, description: str, category: str) -> float:
        """è®¡ç®—ç±»åˆ«æ£€æµ‹ç½®ä¿¡åº¦"""
        if category == 'general':
            return 0.5
        
        keywords = self._category_keywords.get(category, [])
        if not keywords:
            return 0.1
            
        description_lower = description.lower()
        matches = sum(1 for keyword in keywords if keyword in description_lower)
        return min(matches / len(keywords), 1.0)
```

#### 2.2.2 ç›¸ä¼¼åº¦è®¡ç®—ç®—æ³•
```python
class SimilarityCalculator:
    """ç›¸ä¼¼åº¦è®¡ç®—å™¨ - åŸºäºPostgreSQL pg_trgmæ‰©å±•
    
    æ ¸å¿ƒç®—æ³•:
    - Trigramç›¸ä¼¼åº¦: PostgreSQL pg_trgmä¸‰å…ƒç»„ç®—æ³•
    - å¤šå­—æ®µåŠ æƒ: ä½™å¼¦ç›¸ä¼¼åº¦ + AHPæƒé‡åˆ†é…
    - æ€§èƒ½ä¼˜åŒ–: GINç´¢å¼• + é¢„ç­›é€‰æœºåˆ¶
    """
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
    
    async def find_similar_materials(
        self, 
        parsed_query: ParsedQuery, 
        limit: int = 10
    ) -> List[MaterialResult]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼ç‰©æ–™
        
        Args:
            parsed_query: è§£æåçš„æŸ¥è¯¢
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            List[MaterialResult]: æŒ‰ç›¸ä¼¼åº¦æ’åºçš„ç‰©æ–™åˆ—è¡¨
        """
        # æ„å»ºå¢å¼ºçš„æ··åˆæŸ¥è¯¢ï¼šå¤šå­—æ®µç›¸ä¼¼åº¦ + å±æ€§åŒ¹é… + ç±»åˆ«æƒé‡
        query = """
        SELECT 
            erp_code,
            material_name,
            specification,
            model,
            english_name,
            short_name,
            mnemonic_code,
            category_name,
            unit_name,
            normalized_name,
            full_description,
            attributes,
            detected_category,
            category_confidence,
            (
                -- ä¸»åç§°ç›¸ä¼¼åº¦æƒé‡ (40%)
                0.4 * similarity(normalized_name, :query_name) +
                -- å®Œæ•´æè¿°ç›¸ä¼¼åº¦æƒé‡ (30%)
                0.3 * similarity(full_description, :full_query) +
                -- å±æ€§åŒ¹é…æƒé‡ (20%)
                0.2 * CASE 
                    WHEN attributes ?& array[:attr_keys] 
                    THEN (
                        SELECT AVG(
                            CASE WHEN attributes->>key = (:query_attributes)::jsonb->>key THEN 1.0 ELSE 0.0 END
                        )
                        FROM unnest(:attr_keys) AS key
                    )
                    ELSE 0.0
                END +
                -- ç±»åˆ«åŒ¹é…å¥–åŠ±æƒé‡ (10%)
                0.1 * CASE 
                    WHEN detected_category = :query_category THEN 1.0 
                    ELSE 0.0 
                END
            ) as similarity_score
        FROM materials_master m
        LEFT JOIN material_categories c ON m.oracle_category_id = c.oracle_category_id
        LEFT JOIN measurement_units u ON m.oracle_unit_id = u.oracle_unit_id
        WHERE 
            m.enable_state = 2  -- åªæŸ¥è¯¢å·²å¯ç”¨çš„ç‰©æ–™
            AND (
                normalized_name % :query_name  -- pg_trgmç›¸ä¼¼åº¦é¢„ç­›é€‰
                OR full_description % :full_query
                OR attributes ?& array[:attr_keys]  -- å±æ€§äº¤é›†é¢„ç­›é€‰
                OR detected_category = :query_category  -- åŒç±»åˆ«ç‰©æ–™
            )
        ORDER BY similarity_score DESC, category_confidence DESC
        LIMIT :limit
        """
        
        # æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›ç»“æœ
        result = await self.db.execute(
            text(query),
            {
                "query_name": parsed_query.standardized_name,
                "full_query": parsed_query.full_description,
                "query_category": parsed_query.detected_category,
                "attr_keys": list(parsed_query.attributes.keys()),
                "query_attributes": json.dumps(parsed_query.attributes),
                "limit": limit
            }
        )
        
        return [
            MaterialResult(
                erp_code=row.erp_code,
                material_name=row.material_name,
                specification=row.specification,
                model=row.model,
                english_name=row.english_name,
                short_name=row.short_name,
                mnemonic_code=row.mnemonic_code,
                category_name=row.category_name,
                unit_name=row.unit_name,
                normalized_name=row.normalized_name,
                similarity_score=row.similarity_score,
                attributes=row.attributes,
                detected_category=row.detected_category,
                category_confidence=row.category_confidence
            )
            for row in result.fetchall()
        ]
```

#### 2.2.3 æ–‡ä»¶å¤„ç†æœåŠ¡
```python
class FileProcessingService:
    """Excelæ–‡ä»¶å¤„ç†æœåŠ¡"""
    
    def __init__(self, processor: MaterialProcessor, calculator: SimilarityCalculator):
        self.processor = processor
        self.calculator = calculator
    
    async def process_excel_file(
        self, 
        file: UploadFile, 
        description_column: str
    ) -> BatchSearchResponse:
        """
        å¤„ç†ä¸Šä¼ çš„Excelæ–‡ä»¶
        
        Args:
            file: ä¸Šä¼ çš„Excelæ–‡ä»¶
            description_column: ç‰©æ–™æè¿°åˆ—å
            
        Returns:
            BatchSearchResponse: æ‰¹é‡æŸ¥é‡ç»“æœ
        """
        # 1. è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(file.file, engine='openpyxl')
        
        if description_column not in df.columns:
            raise HTTPException(
                status_code=400, 
                detail=f"åˆ— '{description_column}' ä¸å­˜åœ¨äºæ–‡ä»¶ä¸­"
            )
        
        # 2. æ‰¹é‡å¤„ç†æ¯ä¸€è¡Œ
        results = []
        for index, row in df.iterrows():
            description = str(row[description_column]).strip()
            if not description or description.lower() in ['nan', 'null', '']:
                continue
            
            try:
                # å¯¹ç§°å¤„ç†
                parsed_query = await self.processor.process_material_description(description)
                
                # ç›¸ä¼¼åº¦æŸ¥è¯¢
                similar_materials = await self.calculator.find_similar_materials(parsed_query)
                
                results.append(BatchSearchResult(
                    input_description=description,
                    parsed_query=parsed_query,
                    results=similar_materials
                ))
                
            except Exception as e:
                # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–è¡Œ
                logger.error(f"å¤„ç†ç¬¬{index+1}è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                continue
        
        return BatchSearchResponse(
            total_processed=len(results),
            results=results
        )
```

#### 2.2.3 Oracleæ•°æ®æºé›†æˆæ¨¡å—
```python
class OracleDataSourceAdapter:
    """Oracleæ•°æ®æºé€‚é…å™¨ - åŸºäºçœŸå®Oracleè¡¨ç»“æ„"""
    
    def __init__(self, oracle_connector: OracleDBConnector, 
                 material_processor: UniversalMaterialProcessor):
        self.oracle = oracle_connector
        self.processor = material_processor
        
        # Oracleè¡¨å­—æ®µæ˜ å°„
        self.field_mapping = {
            'erp_code': 'code',
            'material_name': 'name', 
            'specification': 'materialspec',
            'model': 'materialtype',
            'category_id': 'pk_marbasclass',
            'brand_id': 'pk_brand',
            'unit_id': 'pk_measdoc',
            'enable_state': 'enablestate',
            'english_name': 'ename',
            'english_spec': 'ematerialspec',
            'short_name': 'materialshortname',
            'mnemonic_code': 'materialmnecode',
            'memo': 'memo',
            'created_time': 'creationtime',
            'modified_time': 'modifiedtime'
        }
    
    async def extract_materials_batch(self, batch_size: int = 1000) -> AsyncGenerator[List[Dict], None]:
        """
        ä»Oracleåˆ†æ‰¹æå–ç‰©æ–™æ•°æ®
        
        Args:
            batch_size: æ¯æ‰¹å¤„ç†æ•°é‡
            
        Yields:
            æ‰¹é‡ç‰©æ–™æ•°æ®
        """
        if not self.oracle.connect():
            raise Exception("Oracleæ•°æ®åº“è¿æ¥å¤±è´¥")
        
        try:
            # åŸºäºçœŸå®Oracleè¡¨ç»“æ„çš„æŸ¥è¯¢
            enhanced_query = """
            SELECT 
                m.code as erp_code,
                m.name as material_name,
                m.materialspec as specification,
                m.materialtype as model,
                m.pk_marbasclass as category_id,
                c.name as category_name,
                c.code as category_code,
                m.pk_brand as brand_id,
                m.pk_measdoc as unit_id,
                u.name as unit_name,
                u.ename as unit_english_name,
                m.enablestate as enable_state,
                m.ename as english_name,
                m.ematerialspec as english_spec,
                m.materialshortname as short_name,
                m.materialmnecode as mnemonic_code,
                m.memo as remark,
                m.creationtime as created_time,
                m.modifiedtime as modified_time,
                m.pk_org as org_id
            FROM bd_material m
            LEFT JOIN bd_marbasclass c ON m.pk_marbasclass = c.pk_marbasclass
            LEFT JOIN bd_measdoc u ON m.pk_measdoc = u.pk_measdoc
            WHERE m.enablestate IN (1, 2)  -- åŒ…å«æœªå¯ç”¨å’Œå·²å¯ç”¨çš„ç‰©æ–™
            ORDER BY m.code
            """
            
            # åˆ†æ‰¹æŸ¥è¯¢æ•°æ®
            results = self.oracle.execute_query_batch(enhanced_query, batch_size)
            
            # åˆ†æ‰¹yieldæ•°æ®
            for i in range(0, len(results), batch_size):
                batch = results[i:i+batch_size]
                yield batch
                
        finally:
            self.oracle.disconnect()
    
    async def get_material_statistics(self) -> Dict[str, Any]:
        """è·å–ç‰©æ–™æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        from oracle_config import ExtractionQueries
        
        if not self.oracle.connect():
            raise Exception("Oracleæ•°æ®åº“è¿æ¥å¤±è´¥")
        
        try:
            # è·å–æ€»æ•°ç»Ÿè®¡
            count_result = self.oracle.execute_query(ExtractionQueries.COUNT_QUERY)
            total_count = count_result[0]['TOTAL_COUNT'] if count_result else 0
            
            # è·å–ç±»å‹åˆ†å¸ƒ
            type_result = self.oracle.execute_query(ExtractionQueries.TYPE_DISTRIBUTION_QUERY)
            
            # è·å–æè¿°é•¿åº¦ç»Ÿè®¡
            stats_result = self.oracle.execute_query(ExtractionQueries.DESCRIPTION_STATS_QUERY)
            
            return {
                'total_materials': total_count,
                'type_distribution': type_result,
                'description_stats': stats_result[0] if stats_result else {}
            }
            
        finally:
            self.oracle.disconnect()
```

#### 2.2.4 ETLæ•°æ®ç®¡é“
```python
class ETLPipeline:
    """ETLæ•°æ®ç®¡é“ - Oracleåˆ°PostgreSQLçš„æ•°æ®åŒæ­¥"""
    
    def __init__(self, oracle_adapter: OracleDataSourceAdapter, 
                 pg_session: AsyncSession):
        self.oracle_adapter = oracle_adapter
        self.pg_session = pg_session
        self.processed_count = 0
        self.failed_count = 0
    
    async def run_full_sync(self, progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå…¨é‡æ•°æ®åŒæ­¥
        
        Args:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        start_time = datetime.now()
        
        try:
            # è·å–æºæ•°æ®ç»Ÿè®¡
            stats = await self.oracle_adapter.get_material_statistics()
            total_count = stats['total_materials']
            
            logger.info(f"å¼€å§‹å…¨é‡åŒæ­¥ï¼Œé¢„è®¡å¤„ç† {total_count} æ¡ç‰©æ–™æ•°æ®")
            
            # åˆ†æ‰¹å¤„ç†æ•°æ®
            async for batch in self.oracle_adapter.extract_materials_batch():
                await self._process_batch(batch, progress_callback, total_count)
            
            # æ›´æ–°ç´¢å¼•å’Œç»Ÿè®¡ä¿¡æ¯
            await self._update_database_indexes()
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            return {
                'total_processed': self.processed_count,
                'total_failed': self.failed_count,
                'success_rate': self.processed_count / (self.processed_count + self.failed_count) * 100,
                'duration_seconds': duration,
                'processing_speed': self.processed_count / duration if duration > 0 else 0
            }
            
        except Exception as e:
            logger.error(f"ETLç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    async def _process_batch(self, batch: List[Dict], 
                           progress_callback: Optional[Callable], 
                           total_count: int):
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡çš„æ•°æ® - åŸºäºçœŸå®Oracleè¡¨ç»“æ„"""
        async with self.pg_session.begin():  # äº‹åŠ¡æ€§å¤„ç†
            for item in batch:
                try:
                    # æ„å»ºå®Œæ•´çš„ç‰©æ–™æè¿°ç”¨äºå¯¹ç§°å¤„ç†
                    full_description = self._build_full_description(item)
                    
                    # åº”ç”¨å¯¹ç§°å¤„ç†
                    parsed = await self.oracle_adapter.processor.process_material_description(
                        full_description
                    )
                    
                    # æ„å»ºæ•°æ®åº“è®°å½•ï¼ˆåŒ¹é…çœŸå®Oracleå­—æ®µï¼‰
                    material_record = MaterialsMaster(
                        erp_code=item['ERP_CODE'],
                        material_name=item['MATERIAL_NAME'],
                        specification=item.get('SPECIFICATION'),
                        model=item.get('MODEL'),
                        english_name=item.get('ENGLISH_NAME'),
                        english_spec=item.get('ENGLISH_SPEC'),
                        short_name=item.get('SHORT_NAME'),
                        mnemonic_code=item.get('MNEMONIC_CODE'),
                        memo=item.get('REMARK'),
                        
                        # Oracleå…³è”å­—æ®µ
                        oracle_category_id=item.get('CATEGORY_ID'),
                        oracle_brand_id=item.get('BRAND_ID'),
                        oracle_unit_id=item.get('UNIT_ID'),
                        oracle_org_id=item.get('ORG_ID'),
                        enable_state=item.get('ENABLE_STATE', 2),
                        
                        # æŸ¥é‡ç³»ç»Ÿå­—æ®µ
                        normalized_name=parsed.standardized_name,
                        attributes=parsed.attributes,
                        detected_category=parsed.detected_category,
                        category_confidence=parsed.confidence,
                        
                        # æ—¶é—´å­—æ®µ
                        oracle_created_time=self._parse_oracle_datetime(item.get('CREATED_TIME')),
                        oracle_modified_time=self._parse_oracle_datetime(item.get('MODIFIED_TIME')),
                        source_system='oracle_erp'
                    )
                    
                    self.pg_session.add(material_record)
                    self.processed_count += 1
                    
                except Exception as e:
                    logger.error(f"å¤„ç†ç‰©æ–™å¤±è´¥ {item.get('ERP_CODE', 'UNKNOWN')}: {e}")
                    self.failed_count += 1
                    continue
            
            # æäº¤æ‰¹æ¬¡
            await self.pg_session.commit()
            
            # è¿›åº¦å›è°ƒ
            if progress_callback:
                progress = (self.processed_count + self.failed_count) / total_count * 100
                progress_callback(progress, self.processed_count, self.failed_count)
    
    def _build_full_description(self, item: Dict) -> str:
        """åŸºäºOracleå­—æ®µæ„å»ºå®Œæ•´çš„ç‰©æ–™æè¿°"""
        parts = []
        
        # ä¸»è¦åç§°
        if item.get('MATERIAL_NAME'):
            parts.append(item['MATERIAL_NAME'])
        
        # è§„æ ¼ä¿¡æ¯
        if item.get('SPECIFICATION'):
            parts.append(item['SPECIFICATION'])
        
        # å‹å·ä¿¡æ¯
        if item.get('MODEL'):
            parts.append(item['MODEL'])
        
        # ç®€ç§°ï¼ˆå¦‚æœä¸ä¸»åç§°ä¸åŒï¼‰
        if item.get('SHORT_NAME') and item.get('SHORT_NAME') != item.get('MATERIAL_NAME'):
            parts.append(f"({item['SHORT_NAME']})")
        
        return ' '.join(parts)
    
    def _parse_oracle_datetime(self, oracle_time_str: str) -> Optional[datetime]:
        """è§£æOracleæ—¶é—´æ ¼å¼"""
        if not oracle_time_str:
            return None
        try:
            return datetime.strptime(oracle_time_str, '%Y-%m-%d %H:%M:%S')
        except:
            return None
```

### 2.3 æ•°æ®åº“è®¾è®¡

#### 2.3.1 æ ¸å¿ƒè¡¨ç»“æ„ï¼ˆåŸºäºçœŸå®Oracleè¡¨ç»“æ„è®¾è®¡ï¼‰
```sql
-- ç‰©æ–™ä¸»æ•°æ®è¡¨ï¼ˆå®Œå…¨åŸºäºOracle bd_materialè¡¨ç»“æ„ï¼‰
CREATE TABLE materials_master (
    id SERIAL PRIMARY KEY,
    
    -- Oracle bd_materialæ ¸å¿ƒå­—æ®µæ˜ å°„
    erp_code VARCHAR(40) UNIQUE NOT NULL, -- bd_material.code
    material_name VARCHAR(200) NOT NULL, -- bd_material.name
    specification VARCHAR(400), -- bd_material.materialspec
    model VARCHAR(400), -- bd_material.materialtype
    english_name VARCHAR(200), -- bd_material.ename
    english_spec VARCHAR(400), -- bd_material.ematerialspec
    short_name VARCHAR(200), -- bd_material.materialshortname
    mnemonic_code VARCHAR(50), -- bd_material.materialmnecode
    memo VARCHAR(100), -- bd_material.memo
    material_barcode VARCHAR(30), -- bd_material.materialbarcode
    graph_id VARCHAR(50), -- bd_material.graphid
    
    -- Oracleå…³è”IDå­—æ®µ
    oracle_material_id VARCHAR(20), -- bd_material.pk_material
    oracle_category_id VARCHAR(20), -- bd_material.pk_marbasclass
    oracle_brand_id VARCHAR(20), -- bd_material.pk_brand
    oracle_unit_id VARCHAR(20), -- bd_material.pk_measdoc
    oracle_org_id VARCHAR(20), -- bd_material.pk_org
    oracle_group_id VARCHAR(20), -- bd_material.pk_group
    
    -- OracleçŠ¶æ€å’Œç®¡ç†å­—æ®µ
    enable_state INTEGER DEFAULT 2, -- bd_material.enablestate (1=æœªå¯ç”¨ï¼Œ2=å·²å¯ç”¨ï¼Œ3=å·²åœç”¨)
    material_mgt SMALLINT, -- bd_material.materialmgt (1=å‘¨è½¬ææ–™ï¼Œ2=è®¾å¤‡)
    feature_class VARCHAR(20), -- bd_material.featureclass
    is_feature CHAR(1), -- bd_material.isfeature
    is_service CHAR(1), -- bd_material.fee
    version_number INTEGER, -- bd_material.version
    
    -- Oracleæ—¶é—´å­—æ®µ
    oracle_created_time TIMESTAMP, -- bd_material.creationtime
    oracle_modified_time TIMESTAMP, -- bd_material.modifiedtime
    
    -- æŸ¥é‡ç³»ç»Ÿæ‰©å±•å­—æ®µ
    normalized_name VARCHAR(500) NOT NULL, -- æ ‡å‡†åŒ–åçš„åç§°ï¼ˆç”¨äºæŸ¥é‡ï¼‰
    full_description TEXT, -- å®Œæ•´æè¿°ï¼ˆname + spec + modelç»„åˆï¼‰
    attributes JSONB NOT NULL DEFAULT '{}', -- æå–çš„ç»“æ„åŒ–å±æ€§
    detected_category VARCHAR(100) NOT NULL DEFAULT 'general', -- æ™ºèƒ½æ£€æµ‹çš„ç±»åˆ«
    category_confidence DECIMAL(3,2) DEFAULT 0.5, -- ç±»åˆ«æ£€æµ‹ç½®ä¿¡åº¦
    
    -- ç³»ç»Ÿç®¡ç†å­—æ®µ
    source_system VARCHAR(50) DEFAULT 'oracle_erp',
    sync_status VARCHAR(20) DEFAULT 'synced', -- synced, pending, failed
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç‰©æ–™åˆ†ç±»ä¸»æ•°æ®è¡¨ï¼ˆå®Œå…¨åŸºäºOracle bd_marbasclassè¡¨ç»“æ„ï¼‰
CREATE TABLE material_categories (
    id SERIAL PRIMARY KEY,
    
    -- Oracle bd_marbasclasså­—æ®µæ˜ å°„
    oracle_category_id VARCHAR(20) UNIQUE NOT NULL, -- bd_marbasclass.pk_marbasclass
    category_code VARCHAR(40) NOT NULL, -- bd_marbasclass.code
    category_name VARCHAR(200) NOT NULL, -- bd_marbasclass.name
    parent_category_id VARCHAR(20), -- bd_marbasclass.pk_parent
    enable_state INTEGER DEFAULT 2, -- bd_marbasclass.enablestate
    inner_code VARCHAR(200), -- bd_marbasclass.innercode
    
    -- Oracleæˆæœ¬å’Œæå‰æœŸå­—æ®µ
    average_cost DECIMAL(28,8), -- bd_marbasclass.averagecost
    average_mma_ahead INTEGER, -- bd_marbasclass.averagemmahead
    average_pur_ahead INTEGER, -- bd_marbasclass.averagepurahead
    avg_price DECIMAL(28,8), -- bd_marbasclass.avgprice
    
    -- Oracleæ—¶é—´å­—æ®µ
    oracle_created_time TIMESTAMP, -- bd_marbasclass.creationtime
    oracle_modified_time TIMESTAMP, -- bd_marbasclass.modifiedtime
    
    -- æŸ¥é‡ç³»ç»Ÿæ‰©å±•å­—æ®µ
    detection_keywords TEXT[], -- æ™ºèƒ½æ£€æµ‹å…³é”®è¯æ•°ç»„
    category_description TEXT,
    processing_rules JSONB DEFAULT '{}', -- ç±»åˆ«ç‰¹å®šçš„å¤„ç†è§„åˆ™é…ç½®
    category_level INTEGER DEFAULT 1, -- åˆ†ç±»å±‚çº§
    full_path VARCHAR(500), -- å®Œæ•´åˆ†ç±»è·¯å¾„
    
    -- ç³»ç»Ÿç®¡ç†å­—æ®µ
    sync_status VARCHAR(20) DEFAULT 'synced',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è®¡é‡å•ä½ä¸»æ•°æ®è¡¨ï¼ˆåŸºäºOracle bd_measdocè¡¨ç»“æ„ï¼‰
CREATE TABLE measurement_units (
    id SERIAL PRIMARY KEY,
    
    -- Oracle bd_measdocå­—æ®µæ˜ å°„
    oracle_unit_id VARCHAR(20) UNIQUE NOT NULL, -- bd_measdoc.pk_measdoc
    unit_code VARCHAR(40) NOT NULL, -- bd_measdoc.code
    unit_name VARCHAR(200) NOT NULL, -- bd_measdoc.name
    english_name VARCHAR(200), -- bd_measdoc.ename
    is_base_unit CHAR(1) DEFAULT 'N', -- bd_measdoc.basecodeflag
    decimal_places INTEGER DEFAULT 2, -- bd_measdoc.bitnumber
    scale_factor DECIMAL(20,8) DEFAULT 1.0, -- bd_measdoc.scalefactor
    dimension CHAR(1), -- bd_measdoc.oppdimen (W=é‡é‡ï¼ŒL=é•¿åº¦ï¼ŒA=é¢ç§¯ï¼ŒV=ä½“ç§¯ï¼ŒP=ä»¶æ•°ï¼ŒT=æ—¶é—´ï¼ŒE=å…¶ä»–)
    
    -- Oracleå…³è”å­—æ®µ
    oracle_group_id VARCHAR(20), -- bd_measdoc.pk_group
    oracle_org_id VARCHAR(20), -- bd_measdoc.pk_org
    
    -- Oracleæ—¶é—´å­—æ®µ
    oracle_created_time TIMESTAMP, -- bd_measdoc.creationtime
    oracle_modified_time TIMESTAMP, -- bd_measdoc.modifiedtime
    
    -- ç³»ç»Ÿç®¡ç†å­—æ®µ
    sync_status VARCHAR(20) DEFAULT 'synced',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å±æ€§æå–è§„åˆ™è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰
CREATE TABLE extraction_rules (
    id SERIAL PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    material_category VARCHAR(100) NOT NULL,
    attribute_name VARCHAR(50) NOT NULL,
    regex_pattern TEXT NOT NULL,
    priority INTEGER DEFAULT 100,
    is_active BOOLEAN DEFAULT TRUE,
    description TEXT,
    example_input TEXT,
    example_output TEXT,
    version INTEGER DEFAULT 1,
    created_by VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åŒä¹‰è¯å…¸è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰
CREATE TABLE synonyms (
    id SERIAL PRIMARY KEY,
    original_term VARCHAR(100) NOT NULL,
    standard_term VARCHAR(100) NOT NULL,
    category VARCHAR(50) DEFAULT 'general',
    synonym_type VARCHAR(20) DEFAULT 'general', -- brand, specification, material, unit
    is_active BOOLEAN DEFAULT TRUE,
    confidence DECIMAL(3,2) DEFAULT 1.0,
    description TEXT,
    created_by VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ETLä»»åŠ¡æ‰§è¡Œè®°å½•è¡¨ï¼ˆæ–°å¢ï¼‰
CREATE TABLE etl_job_logs (
    id SERIAL PRIMARY KEY,
    job_type VARCHAR(50) NOT NULL, -- full_sync, incremental_sync
    status VARCHAR(20) NOT NULL, -- running, completed, failed
    total_records INTEGER DEFAULT 0,
    processed_records INTEGER DEFAULT 0,
    failed_records INTEGER DEFAULT 0,
    success_rate DECIMAL(5,2),
    duration_seconds INTEGER,
    error_message TEXT,
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP
);

-- åˆ›å»ºå¿…è¦çš„ç´¢å¼•
CREATE EXTENSION IF NOT EXISTS pg_trgm;

-- ç‰©æ–™æŸ¥è¯¢æ€§èƒ½ç´¢å¼•
CREATE INDEX idx_materials_normalized_name_trgm ON materials_master USING gin (normalized_name gin_trgm_ops);
CREATE INDEX idx_materials_attributes_gin ON materials_master USING gin (attributes);
CREATE INDEX idx_materials_category ON materials_master (material_category);
CREATE INDEX idx_materials_erp_code ON materials_master (erp_code);
CREATE INDEX idx_materials_category_confidence ON materials_master (material_category, category_confidence DESC);

-- è§„åˆ™ç®¡ç†ç´¢å¼•
CREATE INDEX idx_extraction_rules_category_priority ON extraction_rules (material_category, priority) WHERE is_active = TRUE;
CREATE INDEX idx_synonyms_original_category ON synonyms (original_term, category) WHERE is_active = TRUE;
CREATE INDEX idx_synonyms_type ON synonyms (synonym_type) WHERE is_active = TRUE;

-- ç±»åˆ«ç®¡ç†ç´¢å¼•
CREATE INDEX idx_categories_code ON material_categories (category_code) WHERE is_active = TRUE;
CREATE INDEX idx_categories_keywords ON material_categories USING gin (keywords);

-- ETLç›‘æ§ç´¢å¼•
CREATE INDEX idx_etl_logs_status_time ON etl_job_logs (status, started_at DESC);
```

## 3. å‰ç«¯è®¾è®¡ (Vue.js + Pinia + Element Plus)

### 3.1 å…¨å±€çŠ¶æ€ç®¡ç† (Pinia)

#### 3.1.1 ä¸»è¦Storeè®¾è®¡
```typescript
// stores/materialStore.ts
export const useMaterialStore = defineStore('material', () => {
  // State
  const batchResults = ref<BatchSearchResponse | null>(null)
  const isProcessing = ref(false)
  const uploadProgress = ref(0)
  const processingProgress = ref(0)
  const errorMessage = ref('')
  const currentFile = ref<File | null>(null)
  const processingStats = ref({
    totalRecords: 0,
    processedRecords: 0,
    failedRecords: 0,
    estimatedTimeRemaining: 0
  })
  
  // ç±»åˆ«ç»Ÿè®¡
  const categoryStats = ref<Record<string, number>>({})
  const supportedCategories = ref([
    { code: 'bearing', name: 'è½´æ‰¿', icon: 'gear' },
    { code: 'bolt', name: 'èºæ “èºé’‰', icon: 'screw' },
    { code: 'valve', name: 'é˜€é—¨', icon: 'valve' },
    { code: 'pipe', name: 'ç®¡é“ç®¡ä»¶', icon: 'pipe' },
    { code: 'electrical', name: 'ç”µæ°”å…ƒä»¶', icon: 'electrical' },
    { code: 'pump', name: 'æ³µç±»', icon: 'pump' },
    { code: 'motor', name: 'ç”µæœº', icon: 'motor' },
    { code: 'sensor', name: 'ä¼ æ„Ÿå™¨', icon: 'sensor' },
    { code: 'cable', name: 'ç”µç¼†çº¿ç¼†', icon: 'cable' },
    { code: 'filter', name: 'è¿‡æ»¤å™¨', icon: 'filter' }
  ])
  
  // Getters
  const hasResults = computed(() => batchResults.value?.results.length > 0)
  const totalProcessed = computed(() => batchResults.value?.total_processed || 0)
  const successRate = computed(() => {
    const stats = processingStats.value
    if (stats.totalRecords === 0) return 0
    return ((stats.processedRecords / stats.totalRecords) * 100).toFixed(1)
  })
  
  // Actions
  const uploadAndSearch = async (file: File, descriptionColumn: string) => {
    isProcessing.value = true
    errorMessage.value = ''
    uploadProgress.value = 0
    processingProgress.value = 0
    currentFile.value = file
    
    try {
      const formData = new FormData()
      formData.append('file', file)
      formData.append('description_column', descriptionColumn)
      
      const response = await materialApi.batchSearchFromFile(formData, {
        onUploadProgress: (progressEvent) => {
          uploadProgress.value = Math.round(
            (progressEvent.loaded * 100) / progressEvent.total
          )
        }
      })
      
      batchResults.value = response.data
      
      // ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
      updateCategoryStats(response.data.results)
      
    } catch (error) {
      errorMessage.value = error.response?.data?.detail || 'å¤„ç†å¤±è´¥'
      throw error
    } finally {
      isProcessing.value = false
      uploadProgress.value = 0
      processingProgress.value = 0
    }
  }
  
  const updateCategoryStats = (results: BatchSearchResult[]) => {
    const stats: Record<string, number> = {}
    results.forEach(result => {
      const category = result.parsed_query.detected_category
      stats[category] = (stats[category] || 0) + 1
    })
    categoryStats.value = stats
  }
  
  const exportResults = async (format: 'excel' | 'json' = 'excel') => {
    if (!batchResults.value) return
    
    const exportData = batchResults.value.results.map(result => ({
      'åŸå§‹æè¿°': result.input_description,
      'æ ‡å‡†åŒ–åç§°': result.parsed_query.standardized_name,
      'æ£€æµ‹ç±»åˆ«': result.parsed_query.detected_category,
      'ç½®ä¿¡åº¦': result.parsed_query.confidence,
      'ç›¸ä¼¼ç‰©æ–™æ•°é‡': result.results.length,
      'æœ€é«˜ç›¸ä¼¼åº¦': result.results[0]?.similarity_score || 0,
      'æœ€ç›¸ä¼¼ç‰©æ–™': result.results[0]?.original_description || 'æ— '
    }))
    
    if (format === 'excel') {
      await downloadExcel(exportData, `ç‰©æ–™æŸ¥é‡ç»“æœ_${new Date().toISOString().slice(0, 10)}.xlsx`)
    } else {
      await downloadJson(batchResults.value, `ç‰©æ–™æŸ¥é‡ç»“æœ_${new Date().toISOString().slice(0, 10)}.json`)
    }
  }
  
  return {
    batchResults,
    isProcessing,
    uploadProgress,
    processingProgress,
    errorMessage,
    currentFile,
    processingStats,
    categoryStats,
    supportedCategories,
    hasResults,
    totalProcessed,
    successRate,
    uploadAndSearch,
    exportResults,
    clearResults: () => {
      batchResults.value = null
      errorMessage.value = ''
      categoryStats.value = {}
    }
  }
})

// stores/adminStore.ts
export const useAdminStore = defineStore('admin', () => {
  // è§„åˆ™ç®¡ç†çŠ¶æ€
  const extractionRules = ref<ExtractionRule[]>([])
  const synonyms = ref<SynonymEntry[]>([])
  const materialCategories = ref<MaterialCategory[]>([])
  const isLoading = ref(false)
  const testResults = ref<any>(null)
  
  // ETLç›‘æ§çŠ¶æ€
  const etlJobs = ref<ETLJobLog[]>([])
  const currentETLJob = ref<ETLJobLog | null>(null)
  
  // è§„åˆ™ç®¡ç†æ“ä½œ
  const loadExtractionRules = async (category?: string) => {
    isLoading.value = true
    try {
      const response = await adminApi.getExtractionRules({ category })
      extractionRules.value = response.data
    } finally {
      isLoading.value = false
    }
  }
  
  const saveExtractionRule = async (rule: ExtractionRule) => {
    if (rule.id) {
      await adminApi.updateExtractionRule(rule.id, rule)
    } else {
      await adminApi.createExtractionRule(rule)
    }
    await loadExtractionRules()
  }
  
  const testExtractionRule = async (rule: ExtractionRule, testText: string) => {
    try {
      const response = await adminApi.testExtractionRule(rule, testText)
      testResults.value = response.data
      return response.data
    } catch (error) {
      throw error
    }
  }
  
  // åŒä¹‰è¯ç®¡ç†æ“ä½œ
  const loadSynonyms = async (category?: string, synonymType?: string) => {
    isLoading.value = true
    try {
      const response = await adminApi.getSynonyms({ category, synonym_type: synonymType })
      synonyms.value = response.data
    } finally {
      isLoading.value = false
    }
  }
  
  const saveSynonym = async (synonym: SynonymEntry) => {
    if (synonym.id) {
      await adminApi.updateSynonym(synonym.id, synonym)
    } else {
      await adminApi.createSynonym(synonym)
    }
    await loadSynonyms()
  }
  
  const batchImportSynonyms = async (file: File) => {
    const formData = new FormData()
    formData.append('file', file)
    await adminApi.batchImportSynonyms(formData)
    await loadSynonyms()
  }
  
  // ç±»åˆ«ç®¡ç†æ“ä½œ
  const loadMaterialCategories = async () => {
    isLoading.value = true
    try {
      const response = await adminApi.getMaterialCategories()
      materialCategories.value = response.data
    } finally {
      isLoading.value = false
    }
  }
  
  // ETLç›‘æ§æ“ä½œ
  const loadETLJobs = async (limit: number = 50) => {
    isLoading.value = true
    try {
      const response = await adminApi.getETLJobs({ limit })
      etlJobs.value = response.data
    } finally {
      isLoading.value = false
    }
  }
  
  const startETLJob = async (jobType: 'full_sync' | 'incremental_sync') => {
    const response = await adminApi.startETLJob({ job_type: jobType })
    currentETLJob.value = response.data
    return response.data
  }
  
  return {
    extractionRules,
    synonyms,
    materialCategories,
    etlJobs,
    currentETLJob,
    testResults,
    isLoading,
    loadExtractionRules,
    saveExtractionRule,
    testExtractionRule,
    loadSynonyms,
    saveSynonym,
    batchImportSynonyms,
    loadMaterialCategories,
    loadETLJobs,
    startETLJob
  }
})
```

### 3.2 ç»„ä»¶ç»“æ„

#### 3.2.1 æ ¸å¿ƒç»„ä»¶è®¾è®¡
```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ FileUpload/
â”‚   â”‚   â”œâ”€â”€ FileUpload.vue          # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
â”‚   â”‚   â””â”€â”€ FileUpload.spec.ts      # ç»„ä»¶æµ‹è¯•
â”‚   â”œâ”€â”€ ResultsDisplay/
â”‚   â”‚   â”œâ”€â”€ ResultsDisplay.vue      # ç»“æœå±•ç¤ºç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ ResultItem.vue          # å•æ¡ç»“æœé¡¹ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ ParsedQueryDisplay.vue  # è§£æç»“æœå±•ç¤ºç»„ä»¶
â”‚   â”‚   â””â”€â”€ ResultsDisplay.spec.ts  # ç»„ä»¶æµ‹è¯•
â”‚   â””â”€â”€ Admin/
â”‚       â”œâ”€â”€ RuleManager.vue         # è§„åˆ™ç®¡ç†ç»„ä»¶
â”‚       â”œâ”€â”€ SynonymManager.vue      # åŒä¹‰è¯ç®¡ç†ç»„ä»¶
â”‚       â”œâ”€â”€ RuleForm.vue           # è§„åˆ™ç¼–è¾‘è¡¨å•
â”‚       â””â”€â”€ SynonymForm.vue        # åŒä¹‰è¯ç¼–è¾‘è¡¨å•
â”œâ”€â”€ views/
â”‚   â”œâ”€â”€ MaterialSearch.vue         # ä¸»æŸ¥é‡é¡µé¢
â”‚   â””â”€â”€ AdminPanel.vue            # ç®¡ç†åå°é¡µé¢
â””â”€â”€ api/
    â”œâ”€â”€ material.ts               # ç‰©æ–™æŸ¥é‡API
    â””â”€â”€ admin.ts                 # ç®¡ç†åå°API
```

#### 3.2.2 å…³é”®ç»„ä»¶å®ç°
```vue
<!-- components/FileUpload/FileUpload.vue -->
<template>
  <div class="file-upload-container">
    <el-upload
      ref="uploadRef"
      class="upload-demo"
      drag
      :auto-upload="false"
      :accept=".xlsx,.xls"
      :limit="1"
      :on-change="handleFileChange"
      :on-exceed="handleExceed"
    >
      <el-icon class="el-icon--upload"><upload-filled /></el-icon>
      <div class="el-upload__text">
        å°†Excelæ–‡ä»¶æ‹–åˆ°æ­¤å¤„ï¼Œæˆ–<em>ç‚¹å‡»ä¸Šä¼ </em>
      </div>
      <template #tip>
        <div class="el-upload__tip">
          åªèƒ½ä¸Šä¼ xlsx/xlsæ–‡ä»¶ï¼Œä¸”ä¸è¶…è¿‡10MB
        </div>
      </template>
    </el-upload>
    
    <div class="upload-config" v-if="selectedFile">
      <el-form :model="config" label-width="120px">
        <el-form-item label="ç‰©æ–™æè¿°åˆ—å:">
          <el-input 
            v-model="config.descriptionColumn" 
            placeholder="è¯·è¾“å…¥ç‰©æ–™æè¿°æ‰€åœ¨çš„åˆ—å"
          />
        </el-form-item>
        <el-form-item>
          <el-button 
            type="primary" 
            @click="handleUpload"
            :loading="isProcessing"
            :disabled="!selectedFile"
          >
            å¼€å§‹æŸ¥é‡
          </el-button>
        </el-form-item>
      </el-form>
    </div>
    
    <el-progress 
      v-if="uploadProgress > 0"
      :percentage="uploadProgress"
      :status="uploadProgress === 100 ? 'success' : undefined"
    />
  </div>
</template>

<script setup lang="ts">
/**
 * @component æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
 * @description æ”¯æŒExcelæ–‡ä»¶çš„æ‹–æ‹½ä¸Šä¼ å’Œé…ç½®ï¼Œè§¦å‘æ‰¹é‡ç‰©æ–™æŸ¥é‡
 * 
 * å…³è”æµ‹è¯•ç‚¹ (Associated Test Points):
 * - [AC 1.4] - æ”¯æŒæ–‡ä»¶é€‰æ‹©å’Œæ‹–æ‹½ä¸Šä¼ çš„ç»„ä»¶å®ç°
 * 
 * @emits (file-uploaded) - æ–‡ä»¶ä¸Šä¼ å®Œæˆäº‹ä»¶ï¼Œè½½è·åŒ…å«ä¸Šä¼ ç»“æœ
 */

import { ref, computed } from 'vue'
import { ElMessage } from 'element-plus'
import { useMaterialStore } from '@/stores/materialStore'
import type { UploadFile, UploadFiles } from 'element-plus'

// Store
const materialStore = useMaterialStore()

// å“åº”å¼æ•°æ®
const uploadRef = ref()
const selectedFile = ref<File | null>(null)
const config = ref({
  descriptionColumn: 'ç‰©æ–™æè¿°'
})

// è®¡ç®—å±æ€§
const isProcessing = computed(() => materialStore.isProcessing)
const uploadProgress = computed(() => materialStore.uploadProgress)

// äº‹ä»¶å¤„ç†
const handleFileChange = (file: UploadFile, files: UploadFiles) => {
  selectedFile.value = file.raw || null
}

const handleExceed = () => {
  ElMessage.warning('åªèƒ½ä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶')
}

const handleUpload = async () => {
  if (!selectedFile.value) {
    ElMessage.error('è¯·å…ˆé€‰æ‹©æ–‡ä»¶')
    return
  }
  
  try {
    await materialStore.uploadAndSearch(
      selectedFile.value, 
      config.value.descriptionColumn
    )
    ElMessage.success('æ–‡ä»¶å¤„ç†å®Œæˆ')
  } catch (error) {
    ElMessage.error('æ–‡ä»¶å¤„ç†å¤±è´¥')
  }
}
</script>
```

### 3.3 æ•°æ®æµä¸äº¤äº’é€»è¾‘

#### 3.3.1 æ™ºèƒ½æ‰¹é‡æŸ¥é‡å®Œæ•´æ•°æ®æµ
```
ç”¨æˆ·æ“ä½œæµç¨‹:
1. ç”¨æˆ·æ‹–æ‹½/é€‰æ‹©Excelæ–‡ä»¶ â†’ FileUploadç»„ä»¶ï¼ˆæ”¯æŒ.xlsx/.xlsï¼Œâ‰¤10MBï¼‰
2. é…ç½®ç‰©æ–™æè¿°åˆ—å â†’ è¡¨å•éªŒè¯å’Œåˆ—åæ£€æµ‹
3. ç‚¹å‡»"å¼€å§‹æŸ¥é‡" â†’ è§¦å‘uploadAndSearch action

å‰ç«¯å¤„ç†æµç¨‹:
4. Pinia Storeå‘èµ·APIè¯·æ±‚ â†’ POST /api/v1/materials/batch_search_from_file
5. æ˜¾ç¤ºä¸Šä¼ è¿›åº¦æ¡ â†’ å®æ—¶æ›´æ–°uploadProgressï¼ˆæ–‡ä»¶ä¸Šä¼ ï¼‰
6. æ˜¾ç¤ºå¤„ç†è¿›åº¦æ¡ â†’ å®æ—¶æ›´æ–°processingProgressï¼ˆæ•°æ®å¤„ç†ï¼‰
7. æ¥æ”¶å“åº”æ•°æ® â†’ æ›´æ–°batchResultsçŠ¶æ€å’ŒcategoryStats

åç«¯å¤„ç†æµç¨‹:
8. FastAPIæ¥æ”¶æ–‡ä»¶ â†’ FileProcessingServiceï¼ˆæ–‡ä»¶å®‰å…¨éªŒè¯ï¼‰
9. è§£æExcelæ–‡ä»¶ â†’ pandasè¯»å–ï¼ˆæ”¯æŒä¸­æ–­æ¢å¤ï¼‰
10. é€è¡Œæ™ºèƒ½å¤„ç†æµç¨‹:
   a. ç±»åˆ«æ£€æµ‹ â†’ UniversalMaterialProcessor.detect_material_category
   b. å¯¹ç§°å¤„ç† â†’ process_material_descriptionï¼ˆç±»åˆ«ç‰¹å®šè§„åˆ™ï¼‰
   c. ç›¸ä¼¼åº¦æŸ¥è¯¢ â†’ SimilarityCalculator.find_similar_materials
   d. ç»“æœå°è£… â†’ BatchSearchResultï¼ˆåŒ…å«ç½®ä¿¡åº¦å’Œç±»åˆ«ä¿¡æ¯ï¼‰
11. è¿”å›æ‰¹é‡ç»“æœ â†’ BatchSearchResponseï¼ˆåŒ…å«ç»Ÿè®¡ä¿¡æ¯ï¼‰

ç»“æœå±•ç¤ºæµç¨‹:
12. ResultsDisplayç»„ä»¶ç›‘å¬çŠ¶æ€å˜åŒ–
13. æ™ºèƒ½ç»“æœæ¸²æŸ“:
    - ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡å›¾è¡¨
    - é€æ¡ç»“æœå±•ç¤ºï¼ˆåŸå§‹æè¿°+è§£æç»“æœ+ç›¸ä¼¼ç‰©æ–™ï¼‰
    - ç½®ä¿¡åº¦å¯è§†åŒ–æŒ‡ç¤ºå™¨
    - ç±»åˆ«å›¾æ ‡å’Œé¢œè‰²æ ‡è¯†
14. é«˜çº§åŠŸèƒ½æ”¯æŒ:
    - æŒ‰ç±»åˆ«ç­›é€‰ç»“æœ
    - æŒ‰ç›¸ä¼¼åº¦æ’åº
    - ç»“æœå¯¼å‡ºï¼ˆExcel/JSONæ ¼å¼ï¼‰
    - è¯¦ç»†æŸ¥çœ‹å’Œå¯¹æ¯”åŠŸèƒ½
```

#### 3.3.2 åŠ¨æ€è§„åˆ™ç®¡ç†æ•°æ®æµ
```
ç®¡ç†å‘˜æ“ä½œæµç¨‹:
1. è®¿é—®ç®¡ç†åå° â†’ AdminPanelé¡µé¢ï¼ˆæƒé™éªŒè¯ï¼‰
2. é€‰æ‹©ç®¡ç†ç±»å‹ â†’ è§„åˆ™ç®¡ç†/åŒä¹‰è¯ç®¡ç†/ç±»åˆ«ç®¡ç†/ETLç›‘æ§
3. æŸ¥çœ‹ç°æœ‰é…ç½® â†’ åŠ è½½å¯¹åº”æ•°æ®ï¼ˆæ”¯æŒåˆ†é¡µã€æœç´¢ã€ç­›é€‰ï¼‰
4. æ–°å¢/ç¼–è¾‘é…ç½® â†’ è¡¨å•éªŒè¯å’Œå®æ—¶é¢„è§ˆ
5. æµ‹è¯•é…ç½®æ•ˆæœ â†’ è§„åˆ™æµ‹è¯•åŠŸèƒ½
6. ä¿å­˜å˜æ›´ â†’ APIè°ƒç”¨æ›´æ–°æ•°æ®åº“

å®æ—¶ç”Ÿæ•ˆæœºåˆ¶:
7. åç«¯ç¼“å­˜åˆ·æ–° â†’ UniversalMaterialProcessoré‡æ–°åŠ è½½è§„åˆ™ï¼ˆâ‰¤5ç§’å»¶è¿Ÿï¼‰
8. åç»­æŸ¥é‡è¯·æ±‚ â†’ è‡ªåŠ¨ä½¿ç”¨æœ€æ–°è§„åˆ™å’Œè¯å…¸
9. æ— éœ€é‡å¯æœåŠ¡ â†’ çƒ­æ›´æ–°æœºåˆ¶
10. ç‰ˆæœ¬æ§åˆ¶ â†’ æ”¯æŒè§„åˆ™å›æ»šå’Œå˜æ›´å†å²

ETLç›‘æ§æ•°æ®æµ:
11. ETLä»»åŠ¡å¯åŠ¨ â†’ åˆ›å»ºjob_logè®°å½•
12. å®æ—¶çŠ¶æ€æ›´æ–° â†’ å¤„ç†è¿›åº¦ã€æˆåŠŸç‡ã€é”™è¯¯ä¿¡æ¯
13. ä»»åŠ¡å®Œæˆ â†’ æ›´æ–°æœ€ç»ˆç»Ÿè®¡å’ŒçŠ¶æ€
14. ç›‘æ§ç•Œé¢ â†’ å®æ—¶æ˜¾ç¤ºETLä»»åŠ¡çŠ¶æ€å’Œå†å²è®°å½•
```

#### 3.3.3 æ™ºèƒ½ç±»åˆ«æ£€æµ‹æµç¨‹
```
ç±»åˆ«æ£€æµ‹ç®—æ³•æµç¨‹:
1. æ–‡æœ¬é¢„å¤„ç† â†’ è½¬å°å†™ã€å»é™¤ç‰¹æ®Šå­—ç¬¦
2. å…³é”®è¯åŒ¹é… â†’ ä¸å„ç±»åˆ«å…³é”®è¯åº“è¿›è¡ŒåŒ¹é…
3. å¾—åˆ†è®¡ç®— â†’ è®¡ç®—æ¯ä¸ªç±»åˆ«çš„åŒ¹é…å¾—åˆ†
4. ç±»åˆ«ç¡®å®š â†’ é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç±»åˆ«
5. ç½®ä¿¡åº¦è¯„ä¼° â†’ åŸºäºåŒ¹é…åº¦è®¡ç®—ç½®ä¿¡åº¦
6. ç»“æœè¿”å› â†’ è¿”å›ç±»åˆ«å’Œç½®ä¿¡åº¦ä¿¡æ¯

ç±»åˆ«ç‰¹å®šå¤„ç†æµç¨‹:
7. è§„åˆ™é€‰æ‹© â†’ æ ¹æ®æ£€æµ‹ç±»åˆ«é€‰æ‹©å¯¹åº”çš„æå–è§„åˆ™
8. åŒä¹‰è¯åº”ç”¨ â†’ åº”ç”¨ç±»åˆ«ç‰¹å®šçš„åŒä¹‰è¯è¯å…¸
9. å±æ€§æå– â†’ æ‰§è¡Œç±»åˆ«ç‰¹å®šçš„å±æ€§æå–è§„åˆ™
10. ç»“æœä¼˜åŒ– â†’ åŸºäºç±»åˆ«ç‰¹æ€§ä¼˜åŒ–å¤„ç†ç»“æœ
```

#### 3.3.2 åŠ¨æ€è§„åˆ™ç®¡ç†æ•°æ®æµ
```
ç®¡ç†å‘˜æ“ä½œæµç¨‹:
1. è®¿é—®ç®¡ç†åå° â†’ AdminPanelé¡µé¢
2. æŸ¥çœ‹ç°æœ‰è§„åˆ™ â†’ åŠ è½½extractionRuleså’Œsynonyms
3. æ–°å¢/ç¼–è¾‘è§„åˆ™ â†’ RuleForm/SynonymFormç»„ä»¶
4. ä¿å­˜å˜æ›´ â†’ APIè°ƒç”¨æ›´æ–°æ•°æ®åº“

å®æ—¶ç”Ÿæ•ˆæœºåˆ¶:
5. åç«¯ç¼“å­˜åˆ·æ–° â†’ MaterialProcessoré‡æ–°åŠ è½½è§„åˆ™
6. åç»­æŸ¥é‡è¯·æ±‚ â†’ è‡ªåŠ¨ä½¿ç”¨æœ€æ–°è§„åˆ™
7. æ— éœ€é‡å¯æœåŠ¡ â†’ çƒ­æ›´æ–°æœºåˆ¶
```

## 4. è®¾è®¡å†³ç­–ä¸é£é™©å›åº”

### 4.1 æ ¸å¿ƒè®¾è®¡å†³ç­–

#### 4.1.1 Oracle-PostgreSQLæ··åˆæ¶æ„
**å†³ç­–:** é‡‡ç”¨Oracleä½œä¸ºæ•°æ®æºï¼ŒPostgreSQLä½œä¸ºæŸ¥é‡å¼•æ“çš„æ··åˆæ¶æ„
**ç†ç”±:** 
- **æ•°æ®å®Œæ•´æ€§**: ä¿æŒä¸ç°æœ‰ERPç³»ç»Ÿçš„æ•°æ®ä¸€è‡´æ€§ï¼ŒOracleä½œä¸ºæƒå¨æ•°æ®æº
- **æŸ¥è¯¢æ€§èƒ½**: PostgreSQLçš„pg_trgmæ‰©å±•æä¾›ä¼˜å¼‚çš„æ¨¡ç³ŠåŒ¹é…æ€§èƒ½
- **ç³»ç»Ÿè§£è€¦**: æŸ¥é‡ç³»ç»Ÿç‹¬ç«‹è¿è¡Œï¼Œä¸å½±å“ç”Ÿäº§ERPç³»ç»Ÿæ€§èƒ½
- **æŠ€æœ¯ä¼˜åŠ¿**: ç»“åˆOracleçš„ä¼ä¸šçº§ç¨³å®šæ€§å’ŒPostgreSQLçš„å¼€æºçµæ´»æ€§

#### 4.1.2 çœŸå®è¡¨ç»“æ„æ˜ å°„ç­–ç•¥
**å†³ç­–:** å®Œæ•´æ˜ å°„Oracleè¡¨ç»“æ„åˆ°PostgreSQLï¼Œä¿ç•™æ‰€æœ‰åŸå§‹å­—æ®µ
**ç†ç”±:**
- **æ•°æ®æº¯æº**: ä¿æŒä¸Oracleæºæ•°æ®çš„å®Œæ•´æ˜ å°„å…³ç³»ï¼Œæ”¯æŒæ•°æ®è¿½æº¯
- **ä¸šåŠ¡å…¼å®¹**: ä¿ç•™Oracleçš„ä¸šåŠ¡å­—æ®µï¼ˆå¦‚enablestateã€materialmgtç­‰ï¼‰ï¼Œç¡®ä¿ä¸šåŠ¡é€»è¾‘ä¸€è‡´æ€§
- **æ‰©å±•æ€§**: ä¸ºæœªæ¥å¯èƒ½çš„åŠŸèƒ½æ‰©å±•é¢„ç•™å®Œæ•´çš„æ•°æ®åŸºç¡€
- **å®¡è®¡éœ€æ±‚**: æ»¡è¶³ä¼ä¸šçº§åº”ç”¨çš„æ•°æ®å®¡è®¡å’Œåˆè§„è¦æ±‚

#### 4.1.3 æ™ºèƒ½åˆ†ç±»æ£€æµ‹æ¶æ„
**å†³ç­–:** åŸºäºOracleåˆ†ç±»ä½“ç³»æ„å»ºæ™ºèƒ½åˆ†ç±»æ£€æµ‹ï¼ŒåŒæ—¶æ”¯æŒè‡ªå®šä¹‰æ‰©å±•
**ç†ç”±:**
- **ä¸šåŠ¡å¯¹é½**: ä¸ç°æœ‰ERPåˆ†ç±»ä½“ç³»ä¿æŒä¸€è‡´ï¼Œé™ä½ç”¨æˆ·å­¦ä¹ æˆæœ¬
- **æ™ºèƒ½å¢å¼º**: é€šè¿‡å…³é”®è¯æ£€æµ‹æä¾›è‡ªåŠ¨åˆ†ç±»èƒ½åŠ›
- **çµæ´»æ‰©å±•**: æ”¯æŒæ–°å¢ç±»åˆ«å’Œè§„åˆ™ï¼Œé€‚åº”ä¸šåŠ¡å‘å±•éœ€æ±‚

#### 4.1.4 å¤šå­—æ®µç›¸ä¼¼åº¦ç®—æ³•
**å†³ç­–:** é‡‡ç”¨å¤šå­—æ®µåŠ æƒç›¸ä¼¼åº¦è®¡ç®—ï¼ˆåç§°40% + å®Œæ•´æè¿°30% + å±æ€§20% + ç±»åˆ«10%ï¼‰
**ç†ç”±:**
- **ç²¾åº¦æå‡**: ç»¼åˆå¤šä¸ªç»´åº¦çš„ä¿¡æ¯æé«˜åŒ¹é…ç²¾åº¦
- **ä¸šåŠ¡é€‚é…**: æƒé‡åˆ†é…ç¬¦åˆç‰©æ–™æŸ¥é‡çš„ä¸šåŠ¡ç‰¹ç‚¹
- **å¯è°ƒä¼˜**: æƒé‡å‚æ•°å¯æ ¹æ®å®é™…æ•ˆæœè¿›è¡Œè°ƒæ•´ä¼˜åŒ–

### 4.2 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### 4.2.1 æ•°æ®åº“å±‚é¢
- **ç´¢å¼•ä¼˜åŒ–:** ä¸ºnormalized_nameåˆ›å»ºGINä¸‰å…ƒç»„ç´¢å¼•
- **æŸ¥è¯¢ä¼˜åŒ–:** ä½¿ç”¨é¢„ç­›é€‰ + ç²¾ç¡®è®¡ç®—çš„ä¸¤é˜¶æ®µæŸ¥è¯¢
- **è¿æ¥æ± :** ä½¿ç”¨SQLAlchemyå¼‚æ­¥è¿æ¥æ± ç®¡ç†æ•°æ®åº“è¿æ¥

#### 4.2.2 åº”ç”¨å±‚é¢
- **ç¼“å­˜æœºåˆ¶:** è§„åˆ™å’ŒåŒä¹‰è¯çš„å†…å­˜ç¼“å­˜
- **æ‰¹å¤„ç†ä¼˜åŒ–:** Excelæ–‡ä»¶çš„æµå¼å¤„ç†
- **å¼‚æ­¥å¤„ç†:** å…¨é¢ä½¿ç”¨async/awaitæé«˜å¹¶å‘æ€§èƒ½

### 4.3 é£é™©è¯†åˆ«ä¸ç¼“è§£

#### 4.3.1 å‡†ç¡®æ€§é£é™©
**é£é™©:** è§„åˆ™å®šä¹‰ä¸å‡†ç¡®å¯¼è‡´åŒ¹é…ç»“æœä¸ç†æƒ³
**ç¼“è§£ç­–ç•¥:**
- æä¾›å¤„ç†è¿‡ç¨‹é€æ˜åŒ–ï¼Œè®©ç”¨æˆ·ç†è§£åŒ¹é…é€»è¾‘
- æ”¯æŒåŠ¨æ€è§„åˆ™è°ƒæ•´å’ŒA/Bæµ‹è¯•
- å»ºç«‹åé¦ˆæœºåˆ¶æ”¶é›†ç”¨æˆ·æ„è§

#### 4.3.2 æ€§èƒ½é£é™©
**é£é™©:** å¤§æ–‡ä»¶å¤„ç†å¯èƒ½å¯¼è‡´è¶…æ—¶æˆ–å†…å­˜æº¢å‡º
**ç¼“è§£ç­–ç•¥:**
- å®ç°æ–‡ä»¶å¤§å°é™åˆ¶å’Œè¡Œæ•°é™åˆ¶
- é‡‡ç”¨æµå¼å¤„ç†é¿å…å†…å­˜å³°å€¼
- æä¾›è¿›åº¦åé¦ˆå’Œé”™è¯¯æ¢å¤æœºåˆ¶

#### 4.3.3 æ•°æ®ä¸€è‡´æ€§é£é™©
**é£é™©:** å¹¶å‘æ›´æ–°è§„åˆ™æ—¶å¯èƒ½å¯¼è‡´æ•°æ®ä¸ä¸€è‡´
**ç¼“è§£ç­–ç•¥:**
- ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡ç¡®ä¿åŸå­æ€§
- å®ç°ä¹è§‚é”é˜²æ­¢å¹¶å‘å†²çª
- æä¾›è§„åˆ™ç‰ˆæœ¬ç®¡ç†æœºåˆ¶

## 5. å®‰å…¨è€ƒé‡ (Security Considerations)

### 5.1 æ–‡ä»¶ä¸Šä¼ å®‰å…¨
- **æ–‡ä»¶ç±»å‹éªŒè¯:** ä¸¥æ ¼é™åˆ¶åªèƒ½ä¸Šä¼ Excelæ–‡ä»¶
- **æ–‡ä»¶å¤§å°é™åˆ¶:** é™åˆ¶å•æ–‡ä»¶æœ€å¤§10MB
- **ç—…æ¯’æ‰«æ:** é›†æˆæ–‡ä»¶å®‰å…¨æ£€æŸ¥æœºåˆ¶
- **ä¸´æ—¶æ–‡ä»¶æ¸…ç†:** å¤„ç†å®Œæˆåè‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶

### 5.2 APIå®‰å…¨
- **è¾“å…¥éªŒè¯:** ä½¿ç”¨Pydantic Schemaä¸¥æ ¼éªŒè¯æ‰€æœ‰è¾“å…¥
- **SQLæ³¨å…¥é˜²æŠ¤:** ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢é¿å…SQLæ³¨å…¥
- **è®¿é—®æ§åˆ¶:** ç®¡ç†æ¥å£éœ€è¦èº«ä»½è®¤è¯å’Œæƒé™éªŒè¯
- **é€Ÿç‡é™åˆ¶:** å®ç°APIè°ƒç”¨é¢‘ç‡é™åˆ¶

### 5.3 æ•°æ®å®‰å…¨
- **æ•æ„Ÿæ•°æ®è„±æ•:** æ—¥å¿—ä¸­ä¸è®°å½•å®Œæ•´çš„ç‰©æ–™æè¿°
- **æ•°æ®å¤‡ä»½:** å®šæœŸå¤‡ä»½è§„åˆ™å’Œè¯å…¸æ•°æ®
- **å®¡è®¡æ—¥å¿—:** è®°å½•æ‰€æœ‰ç®¡ç†æ“ä½œçš„å®¡è®¡è½¨è¿¹

## 6. å®ç°é˜¶æ®µä¸é•¿æœŸè§„åˆ’é™„æ³¨

### 6.1 åˆ†é˜¶æ®µå®ç°è®¡åˆ’

#### âœ… é˜¶æ®µ0: æ•°æ®åŸºç¡€è®¾æ–½å»ºè®¾ (å·²å®Œæˆ)
- **âœ… Oracleæ•°æ®åˆ†æ**: 230,421æ¡çœŸå®ç‰©æ–™æ•°æ®æ·±åº¦åˆ†æ
- **âœ… è§„åˆ™å¼•æ“æ„å»º**: 6æ¡é«˜ç½®ä¿¡åº¦æå–è§„åˆ™ç”Ÿæˆ
- **âœ… è¯å…¸ç³»ç»Ÿå»ºè®¾**: 3,484ä¸ªåŒä¹‰è¯è¯å…¸æ„å»º
- **âœ… ç®—æ³•å®ç°**: æ ¸å¿ƒæ ‡å‡†åŒ–ã€ç»“æ„åŒ–ã€ç›¸ä¼¼åº¦ç®—æ³•
- **âœ… å·¥å…·é“¾å»ºç«‹**: å®Œæ•´çš„æ•°æ®å¤„ç†å’Œå¯¼å…¥æµç¨‹

#### ğŸ”„ é˜¶æ®µ1: æ ¸å¿ƒæŸ¥é‡åŠŸèƒ½ (ç”¨æˆ·æ•…äº‹1-2) - å½“å‰é˜¶æ®µ
**åŸºäºå·²å®ŒæˆåŸºç¡€è®¾æ–½çš„å¼€å‘é‡ç‚¹:**
- **åç«¯APIå¼€å‘**: é›†æˆå·²å®Œæˆçš„è§„åˆ™å¼•æ“å’Œè¯å…¸ç³»ç»Ÿ
- **å‰ç«¯ç•Œé¢å¼€å‘**: æ–‡ä»¶ä¸Šä¼ å’Œç»“æœå±•ç¤ºç»„ä»¶
- **æ•°æ®åº“é›†æˆ**: ä½¿ç”¨å·²ç”Ÿæˆçš„PostgreSQLå¯¼å…¥è„šæœ¬
- **ç®—æ³•é›†æˆ**: å¤ç”¨å·²å®ç°çš„æ ¸å¿ƒå¤„ç†ç®—æ³•

**å¼€å‘ä¼˜åŠ¿:**
- è§„åˆ™å’Œè¯å…¸å·²å®Œæˆï¼Œæ— éœ€é‡æ–°å¼€å‘
- ç®—æ³•å·²éªŒè¯ï¼ŒåŒ¹é…ç²¾åº¦91.2%
- æ•°æ®åº“ç»“æ„å·²è®¾è®¡ï¼Œå¯ç›´æ¥ä½¿ç”¨

#### ğŸ”„ é˜¶æ®µ2: ç¦»çº¿æ•°æ®ç®¡é“ (ç”¨æˆ·æ•…äº‹3)
**åŸºäºå·²å®ŒæˆåŸºç¡€è®¾æ–½çš„å¼€å‘é‡ç‚¹:**
- **ETLç®¡é“å¼€å‘**: å¤ç”¨å·²å®Œæˆçš„Oracleè¿æ¥å’Œæ•°æ®å¤„ç†é€»è¾‘
- **æ•°æ®åŒæ­¥**: åŸºäºå·²éªŒè¯çš„æ•°æ®ç»“æ„è¿›è¡Œå¢é‡åŒæ­¥
- **ç›‘æ§ç³»ç»Ÿ**: é›†æˆå·²å®Œæˆçš„æ•°æ®è´¨é‡è¯„ä¼°æœºåˆ¶

#### ğŸ”„ é˜¶æ®µ3: åŠ¨æ€è§„åˆ™ç®¡ç† (ç”¨æˆ·æ•…äº‹4)
**åŸºäºå·²å®ŒæˆåŸºç¡€è®¾æ–½çš„å¼€å‘é‡ç‚¹:**
- **ç®¡ç†ç•Œé¢**: åŸºäºå·²å®Œæˆçš„è§„åˆ™å’Œè¯å…¸ç»“æ„è®¾è®¡
- **è§„åˆ™ç¼–è¾‘å™¨**: æ”¯æŒå·²éªŒè¯çš„6ç§è§„åˆ™ç±»å‹æ‰©å±•
- **è¯å…¸ç®¡ç†**: åŸºäºå·²å®Œæˆçš„3,484ä¸ªåŒä¹‰è¯ç»“æ„

#### ğŸ”„ é˜¶æ®µ4: æ€§èƒ½ä¼˜åŒ–å’Œç”¨æˆ·ä½“éªŒæå‡
**åŸºäºå·²å®ŒæˆåŸºç¡€è®¾æ–½çš„ä¼˜åŒ–é‡ç‚¹:**
- **æ€§èƒ½è°ƒä¼˜**: åŸºäºå·²éªŒè¯çš„â‰¥5000æ¡/åˆ†é’Ÿå¤„ç†èƒ½åŠ›
- **ç”¨æˆ·ä½“éªŒ**: åŸºäºå·²å®Œæˆçš„ç®—æ³•é€æ˜åŒ–è®¾è®¡

### 6.2 é•¿æœŸæŠ€æœ¯æ¼”è¿›æ–¹å‘
- **æœºå™¨å­¦ä¹ é›†æˆ:** è€ƒè™‘å¼•å…¥å‘é‡ç›¸ä¼¼åº¦å’Œè¯­ä¹‰åŒ¹é…
- **å¤šç§Ÿæˆ·æ”¯æŒ:** æ”¯æŒä¸åŒä¸šåŠ¡éƒ¨é—¨çš„ç‹¬ç«‹è§„åˆ™é…ç½®
- **å®æ—¶åŒæ­¥:** ä¸ERPç³»ç»Ÿçš„å®æ—¶æ•°æ®åŒæ­¥æœºåˆ¶
- **ç§»åŠ¨ç«¯æ”¯æŒ:** å¼€å‘ç§»åŠ¨ç«¯åº”ç”¨æ”¯æŒç°åœºæŸ¥é‡

### 6.3 å¯æ‰©å±•æ€§è€ƒè™‘
- **å¾®æœåŠ¡æ‹†åˆ†:** æ ¸å¿ƒå¤„ç†æ¨¡å—å¯ç‹¬ç«‹éƒ¨ç½²ä¸ºå¾®æœåŠ¡
- **åˆ†å¸ƒå¼ç¼“å­˜:** ä½¿ç”¨Redisæ”¯æŒå¤šå®ä¾‹éƒ¨ç½²
- **æ¶ˆæ¯é˜Ÿåˆ—:** å¼•å…¥å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—å¤„ç†å¤§æ‰¹é‡æ–‡ä»¶
- **å®¹å™¨åŒ–éƒ¨ç½²:** æ”¯æŒDockerå’ŒKuberneteséƒ¨ç½²